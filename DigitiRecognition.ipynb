{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def softMax(feature_matrix):\n",
    "    exp_matrix = np.exp(feature_matrix)\n",
    "    denominator = exp_matrix.sum(axis=0)\n",
    "    return exp_matrix / denominator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reLU(x):\n",
    "    return np.maximum(0 , x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeuralNetwork:\n",
    "    def __init__(self, hidden_layers_dimensions, outputs, inputs):\n",
    "        self.input_layer_dimension = inputs.shape[0]\n",
    "        self.hidden_layers_dimensions = hidden_layers_dimensions\n",
    "        self.output_layer_dimension = outputs.shape[0]\n",
    "\n",
    "        self.input_layer = np.array(inputs)\n",
    "        self.output = np.array(outputs)\n",
    "\n",
    "        self.weights = []\n",
    "        self.biases = []\n",
    "\n",
    "        # Input to first hidden layer\n",
    "        self.weights.append(np.random.randn(self.hidden_layers_dimensions[0], self.input_layer_dimension) * 0.1)\n",
    "        self.biases.append(np.zeros((self.hidden_layers_dimensions[0], 1)))\n",
    "\n",
    "        # Hidden layers\n",
    "        for i in range(1, len(self.hidden_layers_dimensions)):\n",
    "            self.weights.append(np.random.randn(self.hidden_layers_dimensions[i], self.hidden_layers_dimensions[i - 1]) * np.sqrt(1 / self.hidden_layers_dimensions[i - 1]))\n",
    "            self.biases.append(np.zeros((self.hidden_layers_dimensions[i], 1)))\n",
    "\n",
    "        # Last hidden layer to output\n",
    "        self.weights.append(np.random.randn(self.output_layer_dimension, self.hidden_layers_dimensions[-1]) * np.sqrt(1 / self.hidden_layers_dimensions[-1]))\n",
    "        self.biases.append(np.zeros((self.output_layer_dimension, 1)))\n",
    "\n",
    "    def forward_propagation(self):\n",
    "        activations = [self.input_layer]\n",
    "        A = self.input_layer\n",
    "\n",
    "        for i in range(len(self.hidden_layers_dimensions)):\n",
    "            Z = np.dot(self.weights[i], A) + self.biases[i]\n",
    "            A = np.tanh(Z)\n",
    "            activations.append(A)\n",
    "\n",
    "        # Output layer - No sigmoid for regression\n",
    "        Z_output = np.dot(self.weights[-1], A) + self.biases[-1]\n",
    "        activations.append(Z_output)\n",
    "\n",
    "        return Z_output, activations\n",
    "\n",
    "    def back_propagation(self, learning_rate=0.01):\n",
    "        output, activations = self.forward_propagation()\n",
    "\n",
    "        # Initialize gradients\n",
    "        d_weights = [np.zeros_like(w) for w in self.weights]\n",
    "        d_biases = [np.zeros_like(b) for b in self.biases]\n",
    "\n",
    "        # Compute output layer error\n",
    "        error = output - self.output\n",
    "        dZ = error  \n",
    "\n",
    "        # Backpropagation through output layer\n",
    "        d_weights[-1] = np.dot(dZ, activations[-2].T)\n",
    "        d_biases[-1] = np.sum(dZ, axis=1, keepdims=True)\n",
    "\n",
    "        # Backpropagation through hidden layers\n",
    "        for i in range(len(self.hidden_layers_dimensions) - 1, -1, -1):\n",
    "            dA = np.dot(self.weights[i + 1].T, dZ)\n",
    "            dZ = dA * (1 - activations[i + 1] ** 2)  # Derivative of tanh activation\n",
    "            d_weights[i] = np.dot(dZ, activations[i].T)\n",
    "            d_biases[i] = np.sum(dZ, axis=1, keepdims=True)\n",
    "\n",
    "        # Update weights and biases\n",
    "        for i in range(len(self.weights)):\n",
    "            self.weights[i] -= learning_rate * d_weights[i]\n",
    "            self.biases[i] -= learning_rate * d_biases[i]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeuralNetworkswithoutTensor:\n",
    "    def __init__(self, hidden_layers_dimensions, outputs, inputs):\n",
    "        self.input_layer_dimension = inputs.shape[0]\n",
    "        self.hidden_layers_dimensions = hidden_layers_dimensions\n",
    "        self.output_layer_dimension = outputs.shape[0]\n",
    "        self.input_layer = np.array(inputs, dtype=np.float32)\n",
    "        self.output = np.array(outputs, dtype=np.float32)\n",
    "\n",
    "        self.weights = []\n",
    "        self.biases = []\n",
    "\n",
    "        # Input to first hidden layer\n",
    "        self.weights.append(np.random.randn(self.hidden_layers_dimensions[0], self.input_layer_dimension) * 0.1)\n",
    "        self.biases.append(np.zeros((self.hidden_layers_dimensions[0], 1), dtype=np.float32))\n",
    "\n",
    "        # Hidden layers\n",
    "        for i in range(1, len(self.hidden_layers_dimensions)):\n",
    "            self.weights.append(np.random.randn(self.hidden_layers_dimensions[i], self.hidden_layers_dimensions[i - 1]) * np.sqrt(1.0 / self.hidden_layers_dimensions[i - 1]))\n",
    "            self.biases.append(np.zeros((self.hidden_layers_dimensions[i], 1), dtype=np.float32))\n",
    "\n",
    "        # Last hidden layer to output (10 neurons for 10 classes)\n",
    "        self.weights.append(np.random.randn(self.output_layer_dimension, self.hidden_layers_dimensions[-1]) * np.sqrt(1.0 / self.hidden_layers_dimensions[-1]))\n",
    "        self.biases.append(np.zeros((self.output_layer_dimension, 1), dtype=np.float32))\n",
    "\n",
    "    def forward_propagation(self, input_data):\n",
    "        activations = [input_data]  \n",
    "        A = input_data\n",
    "\n",
    "        for i in range(len(self.hidden_layers_dimensions)):\n",
    "            Z = np.dot(self.weights[i], A) + self.biases[i]\n",
    "            A = np.maximum(0, Z)  # ReLU Activation\n",
    "            activations.append(A)\n",
    "\n",
    "        # Output layer (Softmax for multi-class classification)\n",
    "        Z_output = np.dot(self.weights[-1], A) + self.biases[-1]\n",
    "        expZ = np.exp(Z_output - np.max(Z_output, axis=0, keepdims=True))  # Stabilized softmax\n",
    "        A_output = expZ / np.sum(expZ, axis=0, keepdims=True)  \n",
    "        activations.append(A_output)\n",
    "\n",
    "        return A_output, activations\n",
    "\n",
    "    def back_propagation(self, learning_rate=0.01):\n",
    "        output, activations = self.forward_propagation(self.input_layer)\n",
    "        \n",
    "        # Compute cross-entropy loss derivative\n",
    "        dZ = output - self.output  \n",
    "\n",
    "        # Initialize gradients\n",
    "        d_weights = [np.zeros_like(w) for w in self.weights]\n",
    "        d_biases = [np.zeros_like(b) for b in self.biases]\n",
    "\n",
    "        # Backpropagation through output layer\n",
    "        d_weights[-1] = np.dot(dZ, activations[-2].T)\n",
    "        d_biases[-1] = np.sum(dZ, axis=1, keepdims=True)\n",
    "\n",
    "        # Backpropagation through hidden layers\n",
    "        for i in range(len(self.hidden_layers_dimensions) - 1, -1, -1):\n",
    "            dA = np.dot(self.weights[i + 1].T, dZ)\n",
    "            dZ = dA * (activations[i + 1] > 0)  # Derivative of ReLU\n",
    "            d_weights[i] = np.dot(dZ, activations[i].T)\n",
    "            d_biases[i] = np.sum(dZ, axis=1, keepdims=True)\n",
    "\n",
    "        # Update weights and biases\n",
    "        for i in range(len(self.weights)):\n",
    "            self.weights[i] -= learning_rate * d_weights[i]\n",
    "            self.biases[i] -= learning_rate * d_biases[i]\n",
    "\n",
    "        # Compute loss (Cross-Entropy)\n",
    "        loss = -np.mean(self.output * np.log(output + 1e-8))  # Avoid log(0)\n",
    "        return loss\n",
    "\n",
    "    def predict(self, inputs):\n",
    "        inputs = np.array(inputs, dtype=np.float32)  # Ensure NumPy array\n",
    "        outputs, _ = self.forward_propagation(inputs)\n",
    "        predictions = np.argmax(outputs, axis=0)  # Get the class with highest probability\n",
    "        return predictions , outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class NeuralNetworks:\n",
    "    def __init__(self, hidden_layers_dimensions, outputs, inputs):\n",
    "        self.input_layer_dimension = inputs.shape[0]\n",
    "        self.hidden_layers_dimensions = hidden_layers_dimensions\n",
    "        self.output_layer_dimension = outputs.shape[0]\n",
    "        self.input_layer = tf.convert_to_tensor(inputs, dtype=tf.float32)\n",
    "        self.output = tf.convert_to_tensor(outputs, dtype=tf.float32)\n",
    "\n",
    "        self.weights = []\n",
    "        self.biases = []\n",
    "\n",
    "        # Input to first hidden layer\n",
    "        self.weights.append(tf.Variable(tf.random.normal([self.hidden_layers_dimensions[0], self.input_layer_dimension], stddev=0.1, dtype=tf.float32)))\n",
    "        self.biases.append(tf.Variable(tf.zeros([self.hidden_layers_dimensions[0], 1], dtype=tf.float32)))\n",
    "\n",
    "        # Hidden layers\n",
    "        for i in range(1, len(self.hidden_layers_dimensions)):\n",
    "            self.weights.append(tf.Variable(tf.random.normal([self.hidden_layers_dimensions[i], self.hidden_layers_dimensions[i - 1]], stddev=tf.sqrt(1.0 / self.hidden_layers_dimensions[i - 1]), dtype=tf.float32)))\n",
    "            self.biases.append(tf.Variable(tf.zeros([self.hidden_layers_dimensions[i], 1], dtype=tf.float32)))\n",
    "\n",
    "        # Last hidden layer to output (10 neurons for 10 classes)\n",
    "        self.weights.append(tf.Variable(tf.random.normal([self.output_layer_dimension, self.hidden_layers_dimensions[-1]], stddev=tf.sqrt(1.0 / self.hidden_layers_dimensions[-1]), dtype=tf.float32)))\n",
    "        self.biases.append(tf.Variable(tf.zeros([self.output_layer_dimension, 1], dtype=tf.float32)))\n",
    "\n",
    "    def forward_propagation(self, input_data):\n",
    "        activations = [input_data]  \n",
    "        A = input_data\n",
    "\n",
    "        for i in range(len(self.hidden_layers_dimensions)):\n",
    "            Z = tf.matmul(self.weights[i], A) + self.biases[i]\n",
    "            A = tf.nn.relu(Z)  # Using ReLU for hidden layers\n",
    "            activations.append(A)\n",
    "\n",
    "        # Output layer (Softmax for multi-class classification)\n",
    "        Z_output = tf.matmul(self.weights[-1], A) + self.biases[-1]\n",
    "        A_output = tf.nn.softmax(Z_output, axis=0)  # Apply softmax activation\n",
    "        activations.append(A_output)\n",
    "\n",
    "        return A_output, activations\n",
    "\n",
    "    def back_propagation(self, learning_rate=0.01):\n",
    "        with tf.GradientTape() as tape:\n",
    "            output, activations = self.forward_propagation(self.input_layer)\n",
    "            loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=output, labels=self.output))  # Cross-entropy loss\n",
    "\n",
    "        # Compute gradients\n",
    "        gradients = tape.gradient(loss, self.weights + self.biases)\n",
    "\n",
    "        # Update weights and biases using Adam optimizer\n",
    "        optimizer = tf.optimizers.Adam(learning_rate)\n",
    "        optimizer.apply_gradients(zip(gradients, self.weights + self.biases))\n",
    "\n",
    "        return loss.numpy()\n",
    "    \n",
    "    def predict(self, inputs):\n",
    "        inputs = tf.convert_to_tensor(inputs, dtype=tf.float32)  # Ensure tensor format\n",
    "        outputs, _ = self.forward_propagation(inputs)  \n",
    "        predictions = tf.argmax(outputs, axis=0)  # Get the class with highest probability\n",
    "        return predictions.numpy() , outputs # Convert tensor to NumPy array for readability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.datasets import mnist\n",
    "\n",
    "# Load MNIST Dataset\n",
    "(train_inputs, train_outputs), (test_inputs, test_outputs) = mnist.load_data()\n",
    "\n",
    "# Flatten images from (28,28) to (784,) and normalize\n",
    "train_inputs = train_inputs.reshape(60000, 784).T / 255.0  # Shape: (784, 60000)\n",
    "test_inputs = test_inputs.reshape(10000, 784).T / 255.0    # Shape: (784, 10000)\n",
    "\n",
    "# Convert labels to one-hot encoding (10 classes)\n",
    "train_outputs = np.eye(10)[train_outputs].T  # Shape: (10, 60000)\n",
    "test_outputs = np.eye(10)[test_outputs].T    # Shape: (10, 10000)\n",
    "\n",
    "# Convert to TensorFlow tensors\n",
    "train_inputs = tf.convert_to_tensor(train_inputs, dtype=tf.float32)\n",
    "train_outputs = tf.convert_to_tensor(train_outputs, dtype=tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss: 65982.640625\n",
      "Epoch 2, Loss: 65052.7890625\n",
      "Epoch 3, Loss: 64162.9140625\n",
      "Epoch 4, Loss: 64197.5234375\n",
      "Epoch 5, Loss: 64254.0\n",
      "Epoch 6, Loss: 65270.9296875\n",
      "Epoch 7, Loss: 65172.30078125\n",
      "Epoch 8, Loss: 64361.75\n",
      "Epoch 9, Loss: 64148.625\n",
      "Epoch 10, Loss: 64404.38671875\n",
      "Epoch 11, Loss: 63645.73828125\n",
      "Epoch 12, Loss: 63819.4296875\n",
      "Epoch 13, Loss: 64073.76171875\n",
      "Epoch 14, Loss: 63349.01171875\n",
      "Epoch 15, Loss: 64015.3203125\n",
      "Epoch 16, Loss: 63201.54296875\n",
      "Epoch 17, Loss: 63580.1015625\n",
      "Epoch 18, Loss: 63738.94921875\n",
      "Epoch 19, Loss: 63097.05078125\n",
      "Epoch 20, Loss: 63415.5234375\n",
      "Epoch 21, Loss: 63359.23828125\n",
      "Epoch 22, Loss: 63208.63671875\n",
      "Epoch 23, Loss: 63202.4609375\n",
      "Epoch 24, Loss: 62968.01171875\n",
      "Epoch 25, Loss: 63534.63671875\n",
      "Epoch 26, Loss: 62896.36328125\n",
      "Epoch 27, Loss: 63280.88671875\n",
      "Epoch 28, Loss: 62892.875\n",
      "Epoch 29, Loss: 63137.75\n",
      "Epoch 30, Loss: 62850.07421875\n",
      "Epoch 31, Loss: 63062.30078125\n",
      "Epoch 32, Loss: 62823.73046875\n",
      "Epoch 33, Loss: 62935.11328125\n",
      "Epoch 34, Loss: 62788.63671875\n",
      "Epoch 35, Loss: 62894.375\n",
      "Epoch 36, Loss: 62775.66796875\n",
      "Epoch 37, Loss: 62879.40625\n",
      "Epoch 38, Loss: 62751.48046875\n",
      "Epoch 39, Loss: 62750.82421875\n",
      "Epoch 40, Loss: 62646.9375\n",
      "Epoch 41, Loss: 62666.44921875\n",
      "Epoch 42, Loss: 62558.7109375\n",
      "Epoch 43, Loss: 62562.875\n",
      "Epoch 44, Loss: 62506.92578125\n",
      "Epoch 45, Loss: 62488.09375\n",
      "Epoch 46, Loss: 62443.1640625\n",
      "Epoch 47, Loss: 62423.6796875\n",
      "Epoch 48, Loss: 62413.38671875\n",
      "Epoch 49, Loss: 62583.63671875\n",
      "Epoch 50, Loss: 62531.25\n",
      "Epoch 51, Loss: 62361.57421875\n",
      "Epoch 52, Loss: 62466.11328125\n",
      "Epoch 53, Loss: 62305.5078125\n",
      "Epoch 54, Loss: 62403.3203125\n",
      "Epoch 55, Loss: 62265.30078125\n",
      "Epoch 56, Loss: 62319.32421875\n",
      "Epoch 57, Loss: 62188.03125\n",
      "Epoch 58, Loss: 62242.09375\n",
      "Epoch 59, Loss: 62114.6640625\n",
      "Epoch 60, Loss: 62193.0703125\n",
      "Epoch 61, Loss: 62051.9765625\n",
      "Epoch 62, Loss: 62142.75\n",
      "Epoch 63, Loss: 62011.53125\n",
      "Epoch 64, Loss: 62124.63671875\n",
      "Epoch 65, Loss: 62110.2421875\n",
      "Epoch 66, Loss: 62086.0390625\n",
      "Epoch 67, Loss: 62064.45703125\n",
      "Epoch 68, Loss: 62008.94921875\n",
      "Epoch 69, Loss: 62029.88671875\n",
      "Epoch 70, Loss: 61946.3515625\n",
      "Epoch 71, Loss: 61992.17578125\n",
      "Epoch 72, Loss: 61906.9140625\n",
      "Epoch 73, Loss: 61970.29296875\n",
      "Epoch 74, Loss: 61888.6171875\n",
      "Epoch 75, Loss: 62003.125\n",
      "Epoch 76, Loss: 61897.94921875\n",
      "Epoch 77, Loss: 61955.45703125\n",
      "Epoch 78, Loss: 61865.98828125\n",
      "Epoch 79, Loss: 61924.94921875\n",
      "Epoch 80, Loss: 61828.73046875\n",
      "Epoch 81, Loss: 61896.88671875\n",
      "Epoch 82, Loss: 61798.05078125\n",
      "Epoch 83, Loss: 61872.21875\n",
      "Epoch 84, Loss: 61772.6953125\n",
      "Epoch 85, Loss: 61848.1484375\n",
      "Epoch 86, Loss: 61752.07421875\n",
      "Epoch 87, Loss: 61822.35546875\n",
      "Epoch 88, Loss: 61727.8359375\n",
      "Epoch 89, Loss: 61791.1875\n",
      "Epoch 90, Loss: 61703.46875\n",
      "Epoch 91, Loss: 61763.4609375\n",
      "Epoch 92, Loss: 61682.98046875\n",
      "Epoch 93, Loss: 61744.375\n",
      "Epoch 94, Loss: 61670.19921875\n",
      "Epoch 95, Loss: 61747.0390625\n",
      "Epoch 96, Loss: 61659.88671875\n",
      "Epoch 97, Loss: 61722.57421875\n",
      "Epoch 98, Loss: 61635.5546875\n",
      "Epoch 99, Loss: 61715.1328125\n",
      "Epoch 100, Loss: 61629.6328125\n",
      "Epoch 101, Loss: 61702.73828125\n",
      "Epoch 102, Loss: 61637.8359375\n",
      "Epoch 103, Loss: 61685.3984375\n",
      "Epoch 104, Loss: 61625.30078125\n",
      "Epoch 105, Loss: 61662.4921875\n",
      "Epoch 106, Loss: 61605.0859375\n",
      "Epoch 107, Loss: 61640.9375\n",
      "Epoch 108, Loss: 61587.40625\n",
      "Epoch 109, Loss: 61619.3359375\n",
      "Epoch 110, Loss: 61572.7109375\n",
      "Epoch 111, Loss: 61602.1015625\n",
      "Epoch 112, Loss: 61560.13671875\n",
      "Epoch 113, Loss: 61589.13671875\n",
      "Epoch 114, Loss: 61548.8515625\n",
      "Epoch 115, Loss: 61576.6640625\n",
      "Epoch 116, Loss: 61540.05078125\n",
      "Epoch 117, Loss: 61576.3828125\n",
      "Epoch 118, Loss: 61548.82421875\n",
      "Epoch 119, Loss: 61582.19921875\n",
      "Epoch 120, Loss: 61554.91796875\n",
      "Epoch 121, Loss: 61584.1875\n",
      "Epoch 122, Loss: 61577.2265625\n",
      "Epoch 123, Loss: 61642.7890625\n",
      "Epoch 124, Loss: 61587.0\n",
      "Epoch 125, Loss: 61606.9140625\n",
      "Epoch 126, Loss: 61569.8046875\n",
      "Epoch 127, Loss: 61581.38671875\n",
      "Epoch 128, Loss: 61556.70703125\n",
      "Epoch 129, Loss: 61571.5234375\n",
      "Epoch 130, Loss: 61543.3828125\n",
      "Epoch 131, Loss: 61553.0625\n",
      "Epoch 132, Loss: 61525.4921875\n",
      "Epoch 133, Loss: 61537.9609375\n",
      "Epoch 134, Loss: 61514.26171875\n",
      "Epoch 135, Loss: 61527.9609375\n",
      "Epoch 136, Loss: 61504.2421875\n",
      "Epoch 137, Loss: 61520.26171875\n",
      "Epoch 138, Loss: 61500.36328125\n",
      "Epoch 139, Loss: 61513.9765625\n",
      "Epoch 140, Loss: 61492.7734375\n",
      "Epoch 141, Loss: 61508.15625\n",
      "Epoch 142, Loss: 61498.26171875\n",
      "Epoch 143, Loss: 61504.4140625\n",
      "Epoch 144, Loss: 61483.7578125\n",
      "Epoch 145, Loss: 61493.30078125\n",
      "Epoch 146, Loss: 61473.19921875\n",
      "Epoch 147, Loss: 61487.8671875\n",
      "Epoch 148, Loss: 61468.3515625\n",
      "Epoch 149, Loss: 61476.32421875\n",
      "Epoch 150, Loss: 61454.4140625\n",
      "Epoch 151, Loss: 61460.9921875\n",
      "Epoch 152, Loss: 61441.0859375\n",
      "Epoch 153, Loss: 61447.0234375\n",
      "Epoch 154, Loss: 61428.05078125\n",
      "Epoch 155, Loss: 61436.3515625\n",
      "Epoch 156, Loss: 61423.3984375\n",
      "Epoch 157, Loss: 61446.0078125\n",
      "Epoch 158, Loss: 61421.23046875\n",
      "Epoch 159, Loss: 61441.4375\n",
      "Epoch 160, Loss: 61413.2421875\n",
      "Epoch 161, Loss: 61428.1953125\n",
      "Epoch 162, Loss: 61402.30078125\n",
      "Epoch 163, Loss: 61418.88671875\n",
      "Epoch 164, Loss: 61398.76171875\n",
      "Epoch 165, Loss: 61413.42578125\n",
      "Epoch 166, Loss: 61398.3125\n",
      "Epoch 167, Loss: 61415.32421875\n",
      "Epoch 168, Loss: 61389.1015625\n",
      "Epoch 169, Loss: 61397.63671875\n",
      "Epoch 170, Loss: 61378.2265625\n",
      "Epoch 171, Loss: 61385.8515625\n",
      "Epoch 172, Loss: 61371.69921875\n",
      "Epoch 173, Loss: 61380.21875\n",
      "Epoch 174, Loss: 61372.08203125\n",
      "Epoch 175, Loss: 61402.53125\n",
      "Epoch 176, Loss: 61459.8828125\n",
      "Epoch 177, Loss: 61399.7109375\n",
      "Epoch 178, Loss: 61436.8515625\n",
      "Epoch 179, Loss: 61387.0\n",
      "Epoch 180, Loss: 61422.48828125\n",
      "Epoch 181, Loss: 61377.0\n",
      "Epoch 182, Loss: 61411.23828125\n",
      "Epoch 183, Loss: 61368.5390625\n",
      "Epoch 184, Loss: 61404.0390625\n",
      "Epoch 185, Loss: 61368.7578125\n",
      "Epoch 186, Loss: 61420.9921875\n",
      "Epoch 187, Loss: 61399.70703125\n",
      "Epoch 188, Loss: 61423.0859375\n",
      "Epoch 189, Loss: 61389.625\n",
      "Epoch 190, Loss: 61409.88671875\n",
      "Epoch 191, Loss: 61376.03125\n",
      "Epoch 192, Loss: 61399.5234375\n",
      "Epoch 193, Loss: 61364.58203125\n",
      "Epoch 194, Loss: 61391.125\n",
      "Epoch 195, Loss: 61357.80078125\n",
      "Epoch 196, Loss: 61389.0234375\n",
      "Epoch 197, Loss: 61354.3984375\n",
      "Epoch 198, Loss: 61384.82421875\n",
      "Epoch 199, Loss: 61344.23828125\n",
      "Epoch 200, Loss: 61377.4609375\n",
      "Epoch 201, Loss: 61341.7109375\n",
      "Epoch 202, Loss: 61372.6953125\n",
      "Epoch 203, Loss: 61332.5\n",
      "Epoch 204, Loss: 61365.6640625\n",
      "Epoch 205, Loss: 61325.625\n",
      "Epoch 206, Loss: 61364.5\n",
      "Epoch 207, Loss: 61326.13671875\n",
      "Epoch 208, Loss: 61369.98046875\n",
      "Epoch 209, Loss: 61335.2734375\n",
      "Epoch 210, Loss: 61401.4140625\n",
      "Epoch 211, Loss: 61354.05078125\n",
      "Epoch 212, Loss: 61397.03125\n",
      "Epoch 213, Loss: 61345.61328125\n",
      "Epoch 214, Loss: 61388.5625\n",
      "Epoch 215, Loss: 61342.2890625\n",
      "Epoch 216, Loss: 61378.25\n",
      "Epoch 217, Loss: 61335.36328125\n",
      "Epoch 218, Loss: 61369.0625\n",
      "Epoch 219, Loss: 61327.0\n",
      "Epoch 220, Loss: 61360.04296875\n",
      "Epoch 221, Loss: 61318.0859375\n",
      "Epoch 222, Loss: 61353.57421875\n",
      "Epoch 223, Loss: 61314.89453125\n",
      "Epoch 224, Loss: 61349.73828125\n",
      "Epoch 225, Loss: 61309.71875\n",
      "Epoch 226, Loss: 61343.5\n",
      "Epoch 227, Loss: 61300.7890625\n",
      "Epoch 228, Loss: 61336.51953125\n",
      "Epoch 229, Loss: 61296.71875\n",
      "Epoch 230, Loss: 61330.9609375\n",
      "Epoch 231, Loss: 61293.125\n",
      "Epoch 232, Loss: 61325.07421875\n",
      "Epoch 233, Loss: 61289.3515625\n",
      "Epoch 234, Loss: 61326.8203125\n",
      "Epoch 235, Loss: 61298.28125\n",
      "Epoch 236, Loss: 61335.51171875\n",
      "Epoch 237, Loss: 61304.6328125\n",
      "Epoch 238, Loss: 61332.1015625\n",
      "Epoch 239, Loss: 61297.33203125\n",
      "Epoch 240, Loss: 61325.60546875\n",
      "Epoch 241, Loss: 61290.53125\n",
      "Epoch 242, Loss: 61320.57421875\n",
      "Epoch 243, Loss: 61289.6171875\n",
      "Epoch 244, Loss: 61312.7265625\n",
      "Epoch 245, Loss: 61287.1171875\n",
      "Epoch 246, Loss: 61305.07421875\n",
      "Epoch 247, Loss: 61280.2890625\n",
      "Epoch 248, Loss: 61297.80078125\n",
      "Epoch 249, Loss: 61279.3359375\n",
      "Epoch 250, Loss: 61288.1640625\n",
      "Epoch 251, Loss: 61276.3125\n",
      "Epoch 252, Loss: 61284.9609375\n",
      "Epoch 253, Loss: 61269.3515625\n",
      "Epoch 254, Loss: 61278.7109375\n",
      "Epoch 255, Loss: 61263.40625\n",
      "Epoch 256, Loss: 61272.69921875\n",
      "Epoch 257, Loss: 61265.6171875\n",
      "Epoch 258, Loss: 61283.26171875\n",
      "Epoch 259, Loss: 61290.1875\n",
      "Epoch 260, Loss: 61319.88671875\n",
      "Epoch 261, Loss: 61304.57421875\n",
      "Epoch 262, Loss: 61310.6484375\n",
      "Epoch 263, Loss: 61300.82421875\n",
      "Epoch 264, Loss: 61307.7265625\n",
      "Epoch 265, Loss: 61300.8984375\n",
      "Epoch 266, Loss: 61299.0546875\n",
      "Epoch 267, Loss: 61298.5390625\n",
      "Epoch 268, Loss: 61289.1015625\n",
      "Epoch 269, Loss: 61293.98046875\n",
      "Epoch 270, Loss: 61279.1015625\n",
      "Epoch 271, Loss: 61292.75\n",
      "Epoch 272, Loss: 61267.36328125\n",
      "Epoch 273, Loss: 61290.15625\n",
      "Epoch 274, Loss: 61266.39453125\n",
      "Epoch 275, Loss: 61290.0625\n",
      "Epoch 276, Loss: 61264.0078125\n",
      "Epoch 277, Loss: 61289.5546875\n",
      "Epoch 278, Loss: 61259.9375\n",
      "Epoch 279, Loss: 61283.8984375\n",
      "Epoch 280, Loss: 61259.98046875\n",
      "Epoch 281, Loss: 61291.55078125\n",
      "Epoch 282, Loss: 61268.46875\n",
      "Epoch 283, Loss: 61292.70703125\n",
      "Epoch 284, Loss: 61258.19921875\n",
      "Epoch 285, Loss: 61285.11328125\n",
      "Epoch 286, Loss: 61250.7890625\n",
      "Epoch 287, Loss: 61282.82421875\n",
      "Epoch 288, Loss: 61251.44921875\n",
      "Epoch 289, Loss: 61285.3046875\n",
      "Epoch 290, Loss: 61267.8828125\n",
      "Epoch 291, Loss: 61278.17578125\n",
      "Epoch 292, Loss: 61260.4375\n",
      "Epoch 293, Loss: 61274.6015625\n",
      "Epoch 294, Loss: 61265.3359375\n",
      "Epoch 295, Loss: 61271.55078125\n",
      "Epoch 296, Loss: 61261.1640625\n",
      "Epoch 297, Loss: 61267.9609375\n",
      "Epoch 298, Loss: 61264.1875\n",
      "Epoch 299, Loss: 61257.95703125\n",
      "Epoch 300, Loss: 61261.0546875\n",
      "Epoch 301, Loss: 61254.0\n",
      "Epoch 302, Loss: 61256.83203125\n",
      "Epoch 303, Loss: 61249.19921875\n",
      "Epoch 304, Loss: 61254.9140625\n",
      "Epoch 305, Loss: 61246.21875\n",
      "Epoch 306, Loss: 61253.8984375\n",
      "Epoch 307, Loss: 61242.1328125\n",
      "Epoch 308, Loss: 61246.09375\n",
      "Epoch 309, Loss: 61235.8828125\n",
      "Epoch 310, Loss: 61241.0390625\n",
      "Epoch 311, Loss: 61238.3515625\n",
      "Epoch 312, Loss: 61237.7265625\n",
      "Epoch 313, Loss: 61234.125\n",
      "Epoch 314, Loss: 61234.61328125\n",
      "Epoch 315, Loss: 61227.0859375\n",
      "Epoch 316, Loss: 61230.9140625\n",
      "Epoch 317, Loss: 61237.625\n",
      "Epoch 318, Loss: 61225.7265625\n",
      "Epoch 319, Loss: 61233.69921875\n",
      "Epoch 320, Loss: 61238.15625\n",
      "Epoch 321, Loss: 61234.3984375\n",
      "Epoch 322, Loss: 61248.67578125\n",
      "Epoch 323, Loss: 61257.7578125\n",
      "Epoch 324, Loss: 61247.42578125\n",
      "Epoch 325, Loss: 61249.04296875\n",
      "Epoch 326, Loss: 61238.6484375\n",
      "Epoch 327, Loss: 61249.10546875\n",
      "Epoch 328, Loss: 61234.13671875\n",
      "Epoch 329, Loss: 61242.5234375\n",
      "Epoch 330, Loss: 61228.26171875\n",
      "Epoch 331, Loss: 61235.60546875\n",
      "Epoch 332, Loss: 61221.8125\n",
      "Epoch 333, Loss: 61229.98828125\n",
      "Epoch 334, Loss: 61219.95703125\n",
      "Epoch 335, Loss: 61229.10546875\n",
      "Epoch 336, Loss: 61218.01171875\n",
      "Epoch 337, Loss: 61227.5234375\n",
      "Epoch 338, Loss: 61217.3515625\n",
      "Epoch 339, Loss: 61232.5625\n",
      "Epoch 340, Loss: 61220.30078125\n",
      "Epoch 341, Loss: 61236.28125\n",
      "Epoch 342, Loss: 61226.86328125\n",
      "Epoch 343, Loss: 61252.3125\n",
      "Epoch 344, Loss: 61219.0859375\n",
      "Epoch 345, Loss: 61249.9140625\n",
      "Epoch 346, Loss: 61211.82421875\n",
      "Epoch 347, Loss: 61250.55078125\n",
      "Epoch 348, Loss: 61209.3515625\n",
      "Epoch 349, Loss: 61247.9375\n",
      "Epoch 350, Loss: 61204.54296875\n",
      "Epoch 351, Loss: 61241.61328125\n",
      "Epoch 352, Loss: 61196.3125\n",
      "Epoch 353, Loss: 61236.96875\n",
      "Epoch 354, Loss: 61192.1875\n",
      "Epoch 355, Loss: 61240.21875\n",
      "Epoch 356, Loss: 61203.04296875\n",
      "Epoch 357, Loss: 61241.17578125\n",
      "Epoch 358, Loss: 61202.92578125\n",
      "Epoch 359, Loss: 61232.30078125\n",
      "Epoch 360, Loss: 61201.3984375\n",
      "Epoch 361, Loss: 61241.38671875\n",
      "Epoch 362, Loss: 61200.5078125\n",
      "Epoch 363, Loss: 61241.3828125\n",
      "Epoch 364, Loss: 61200.83203125\n",
      "Epoch 365, Loss: 61244.60546875\n",
      "Epoch 366, Loss: 61197.8515625\n",
      "Epoch 367, Loss: 61233.5390625\n",
      "Epoch 368, Loss: 61198.2890625\n",
      "Epoch 369, Loss: 61232.1953125\n",
      "Epoch 370, Loss: 61202.69921875\n",
      "Epoch 371, Loss: 61240.17578125\n",
      "Epoch 372, Loss: 61205.82421875\n",
      "Epoch 373, Loss: 61230.3984375\n",
      "Epoch 374, Loss: 61206.01171875\n",
      "Epoch 375, Loss: 61223.07421875\n",
      "Epoch 376, Loss: 61203.65625\n",
      "Epoch 377, Loss: 61215.61328125\n",
      "Epoch 378, Loss: 61204.21875\n",
      "Epoch 379, Loss: 61215.92578125\n",
      "Epoch 380, Loss: 61201.5859375\n",
      "Epoch 381, Loss: 61210.44921875\n",
      "Epoch 382, Loss: 61194.86328125\n",
      "Epoch 383, Loss: 61204.01953125\n",
      "Epoch 384, Loss: 61194.4609375\n",
      "Epoch 385, Loss: 61212.36328125\n",
      "Epoch 386, Loss: 61202.28125\n",
      "Epoch 387, Loss: 61200.8515625\n",
      "Epoch 388, Loss: 61194.6015625\n",
      "Epoch 389, Loss: 61194.26171875\n",
      "Epoch 390, Loss: 61190.625\n",
      "Epoch 391, Loss: 61202.8203125\n",
      "Epoch 392, Loss: 61191.48828125\n",
      "Epoch 393, Loss: 61203.875\n",
      "Epoch 394, Loss: 61187.6953125\n",
      "Epoch 395, Loss: 61199.51953125\n",
      "Epoch 396, Loss: 61189.23046875\n",
      "Epoch 397, Loss: 61214.4375\n",
      "Epoch 398, Loss: 61189.0703125\n",
      "Epoch 399, Loss: 61204.92578125\n",
      "Epoch 400, Loss: 61189.7890625\n",
      "Epoch 401, Loss: 61201.625\n",
      "Epoch 402, Loss: 61191.1484375\n",
      "Epoch 403, Loss: 61192.39453125\n",
      "Epoch 404, Loss: 61188.9609375\n",
      "Epoch 405, Loss: 61192.6875\n",
      "Epoch 406, Loss: 61184.5234375\n",
      "Epoch 407, Loss: 61189.6640625\n",
      "Epoch 408, Loss: 61182.0\n",
      "Epoch 409, Loss: 61184.7265625\n",
      "Epoch 410, Loss: 61179.30078125\n",
      "Epoch 411, Loss: 61179.3203125\n",
      "Epoch 412, Loss: 61171.29296875\n",
      "Epoch 413, Loss: 61171.58203125\n",
      "Epoch 414, Loss: 61169.21875\n",
      "Epoch 415, Loss: 61168.7890625\n",
      "Epoch 416, Loss: 61165.2265625\n",
      "Epoch 417, Loss: 61174.875\n",
      "Epoch 418, Loss: 61186.13671875\n",
      "Epoch 419, Loss: 61172.92578125\n",
      "Epoch 420, Loss: 61183.23828125\n",
      "Epoch 421, Loss: 61186.03125\n",
      "Epoch 422, Loss: 61179.07421875\n",
      "Epoch 423, Loss: 61182.95703125\n",
      "Epoch 424, Loss: 61180.98828125\n",
      "Epoch 425, Loss: 61182.71875\n",
      "Epoch 426, Loss: 61177.73828125\n",
      "Epoch 427, Loss: 61178.3515625\n",
      "Epoch 428, Loss: 61171.01171875\n",
      "Epoch 429, Loss: 61179.13671875\n",
      "Epoch 430, Loss: 61172.05078125\n",
      "Epoch 431, Loss: 61179.98828125\n",
      "Epoch 432, Loss: 61170.0859375\n",
      "Epoch 433, Loss: 61174.07421875\n",
      "Epoch 434, Loss: 61166.8125\n",
      "Epoch 435, Loss: 61170.73828125\n",
      "Epoch 436, Loss: 61173.0078125\n",
      "Epoch 437, Loss: 61186.8515625\n",
      "Epoch 438, Loss: 61182.70703125\n",
      "Epoch 439, Loss: 61189.23828125\n",
      "Epoch 440, Loss: 61181.19921875\n",
      "Epoch 441, Loss: 61183.1484375\n",
      "Epoch 442, Loss: 61175.6171875\n",
      "Epoch 443, Loss: 61188.1484375\n",
      "Epoch 444, Loss: 61183.91796875\n",
      "Epoch 445, Loss: 61181.73828125\n",
      "Epoch 446, Loss: 61174.9140625\n",
      "Epoch 447, Loss: 61183.96875\n",
      "Epoch 448, Loss: 61177.48046875\n",
      "Epoch 449, Loss: 61178.3515625\n",
      "Epoch 450, Loss: 61173.6953125\n",
      "Epoch 451, Loss: 61171.44921875\n",
      "Epoch 452, Loss: 61172.11328125\n",
      "Epoch 453, Loss: 61171.3984375\n",
      "Epoch 454, Loss: 61175.86328125\n",
      "Epoch 455, Loss: 61168.4140625\n",
      "Epoch 456, Loss: 61183.04296875\n",
      "Epoch 457, Loss: 61169.86328125\n",
      "Epoch 458, Loss: 61183.3125\n",
      "Epoch 459, Loss: 61162.14453125\n",
      "Epoch 460, Loss: 61180.8515625\n",
      "Epoch 461, Loss: 61163.61328125\n",
      "Epoch 462, Loss: 61178.46875\n",
      "Epoch 463, Loss: 61160.8046875\n",
      "Epoch 464, Loss: 61174.40625\n",
      "Epoch 465, Loss: 61158.17578125\n",
      "Epoch 466, Loss: 61172.25\n",
      "Epoch 467, Loss: 61151.73828125\n",
      "Epoch 468, Loss: 61174.11328125\n",
      "Epoch 469, Loss: 61155.4375\n",
      "Epoch 470, Loss: 61167.17578125\n",
      "Epoch 471, Loss: 61154.8515625\n",
      "Epoch 472, Loss: 61166.5546875\n",
      "Epoch 473, Loss: 61159.30078125\n",
      "Epoch 474, Loss: 61161.92578125\n",
      "Epoch 475, Loss: 61155.9296875\n",
      "Epoch 476, Loss: 61168.03125\n",
      "Epoch 477, Loss: 61161.98828125\n",
      "Epoch 478, Loss: 61184.25\n",
      "Epoch 479, Loss: 61169.3515625\n",
      "Epoch 480, Loss: 61173.2109375\n",
      "Epoch 481, Loss: 61164.3125\n",
      "Epoch 482, Loss: 61167.5234375\n",
      "Epoch 483, Loss: 61166.32421875\n",
      "Epoch 484, Loss: 61165.1953125\n",
      "Epoch 485, Loss: 61160.8359375\n",
      "Epoch 486, Loss: 61162.30078125\n",
      "Epoch 487, Loss: 61160.11328125\n",
      "Epoch 488, Loss: 61156.1875\n",
      "Epoch 489, Loss: 61154.67578125\n",
      "Epoch 490, Loss: 61159.9375\n",
      "Epoch 491, Loss: 61153.98828125\n",
      "Epoch 492, Loss: 61155.7265625\n",
      "Epoch 493, Loss: 61152.45703125\n",
      "Epoch 494, Loss: 61154.75\n",
      "Epoch 495, Loss: 61157.2734375\n",
      "Epoch 496, Loss: 61147.8515625\n",
      "Epoch 497, Loss: 61156.30078125\n",
      "Epoch 498, Loss: 61147.0\n",
      "Epoch 499, Loss: 61165.6171875\n",
      "Epoch 500, Loss: 61152.4765625\n"
     ]
    }
   ],
   "source": [
    "# Initialize Model\n",
    "hidden_layer_dimensions = [128, 64]  # Two hidden layers with 128 and 64 neurons\n",
    "brain_one = NeuralNetworks(hidden_layer_dimensions, train_outputs, train_inputs)\n",
    "\n",
    "# Train the Model\n",
    "epochs = 500\n",
    "for epoch in range(epochs):\n",
    "    loss = brain_one.back_propagation(learning_rate=0.01)\n",
    "    if epoch % 1 == 0:\n",
    "        print(f\"Epoch {epoch+1}, Loss: {loss}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'NeuralNetworkswithoutTensor' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 16\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[38;5;66;03m# Initialize Model\u001b[39;00m\n\u001b[1;32m     15\u001b[0m hidden_layer_dimensions \u001b[38;5;241m=\u001b[39m [\u001b[38;5;241m128\u001b[39m, \u001b[38;5;241m64\u001b[39m]\n\u001b[0;32m---> 16\u001b[0m brain_one \u001b[38;5;241m=\u001b[39m NeuralNetworkswithoutTensor(hidden_layer_dimensions, train_outputs, train_inputs)\n\u001b[1;32m     18\u001b[0m \u001b[38;5;66;03m# Train the Model\u001b[39;00m\n\u001b[1;32m     19\u001b[0m epochs \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m10\u001b[39m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'NeuralNetworkswithoutTensor' is not defined"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.datasets import mnist\n",
    "\n",
    "# Load MNIST Dataset\n",
    "(train_inputs, train_outputs), (test_inputs, test_outputs) = mnist.load_data()\n",
    "\n",
    "# Flatten images from (28,28) to (784,) and normalize\n",
    "train_inputs = train_inputs.reshape(60000, 784).T / 255.0  # Shape: (784, 60000)\n",
    "test_inputs = test_inputs.reshape(10000, 784).T / 255.0    # Shape: (784, 10000)\n",
    "\n",
    "# Convert labels to one-hot encoding (10 classes)\n",
    "train_outputs = np.eye(10)[train_outputs].T  # Shape: (10, 60000)\n",
    "test_outputs = np.eye(10)[test_outputs].T    # Shape: (10, 10000)\n",
    "\n",
    "# Initialize Model\n",
    "hidden_layer_dimensions = [128, 64]\n",
    "brain_one = NeuralNetworkswithoutTensor(hidden_layer_dimensions, train_outputs, train_inputs)\n",
    "\n",
    "# Train the Model\n",
    "epochs = 10\n",
    "for epoch in range(epochs):\n",
    "    loss = brain_one.back_propagation(learning_rate=0.01)\n",
    "    print(f\"Epoch {epoch+1}, Loss: {loss}\")\n",
    "\n",
    "# Make Predictions\n",
    "A_output = brain_one.predict(test_inputs[:, 100].reshape(-1, 1))\n",
    "print(\"Predicted Digit:\", A_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAewAAAGiCAYAAAAlePV8AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjkuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8hTgPZAAAACXBIWXMAAA9hAAAPYQGoP6dpAAAr+UlEQVR4nO3dfXRV1bnv8d8mwA5qEg9g3iSmsYVTrrFUEyuJBJGW1NgyitgrreMKtOAwDS8XI1aRMUpKe0hLrxzaUqK0vMgptFxbVDrMEHMGJkCRHqChcoBrsUQTNWlGUk3Ci0nJnvePlF23CZC1195JZtb30zHHIGuvZ8+Z1SUPz1wv02eMMQIAAAPakP4eAAAAuDISNgAAFiBhAwBgARI2AAAWIGEDAGABEjYAABYgYQMAYAESNgAAFiBhAwBgARI2AAAWIGEDAODA3r17NX36dKWmpsrn8+mFF164YkxVVZWysrIUGxurG2+8UU8//bTjfknYAAA4cPbsWU2YMEHr1q3r1f41NTW65557lJeXp+rqaj355JNavHixfvvb3zrq18fiHwAAhMfn8+n555/XjBkzLrnP448/rl27dunkyZPBbYWFhfrTn/6k1157rdd9DXUz0GgIBAJ67733FBcXJ5/P19/DAQA4ZIxRW1ubUlNTNWRI9CZyP/zwQ3V0dLj+HmNMt3zj9/vl9/tdf7ckvfbaa8rPzw/Z9sUvflEbN27U3//+dw0bNqxX3zPgEvZ7772ntLS0/h4GAMCluro6jRkzJirf/eGHHyoj/Ro1NHa6/q5rrrlGZ86cCdm2YsUKlZSUuP5uSWpoaFBSUlLItqSkJF24cEFNTU1KSUnp1fcMuIQdFxcnSZqkezRUvftXBwBg4Ligv2u/yoN/n0dDR0eHGho7VXMkXfFx4VfxrW0BZWS9rbq6OsXHxwe3R6q6vujjFfzFq9FOZpIHXMK+OPihGqahPhI2AFjnH3dG9cVlzfi4Ia4SdvB74uNDEnYkJScnq6GhIWRbY2Ojhg4dqlGjRvX6e6J2cWH9+vXKyMhQbGyssrKytG/fvmh1BQDwqE4TcN2iLScnRxUVFSHbXnnlFWVnZ/f6+rUUpYS9Y8cOLVmyRMuXL1d1dbXy8vJUUFCg2traaHQHAPCogIzr5tSZM2d09OhRHT16VFLXY1tHjx4N5rhly5Zp9uzZwf0LCwv19ttvq7i4WCdPntSmTZu0ceNGLV261FG/UUnYa9as0bx58zR//nyNHz9ea9euVVpamsrKyrrt297ertbW1pAGAEBvBCLwP6cOHz6sW265Rbfccoskqbi4WLfccou+853vSJLq6+tDCtSMjAyVl5ersrJSn/3sZ/W9731PP/nJT3Tfffc56jfi17A7Ojp05MgRPfHEEyHb8/PzdeDAgW77l5aW6rvf/W6khwEAQFRMmTJFl3uFyZYtW7ptu/POO/XHP/7RVb8Rr7CbmprU2dnZ4y3sH7/oLnVNHbS0tARbXV1dpIcEABikOo1x3WwRtbvEe7qFvac7BiP5cDoAwFvCvQ790XhbRLzCHj16tGJiYnq8hf3jVTcAAOidiCfs4cOHKysrq9st7BUVFcrNzY10dwAADwvIqNNFs6nCjsqUeHFxsR588EFlZ2crJydHGzZsUG1trQoLC6PRHQDAo7w0JR6VhD1r1iw1Nzdr5cqVqq+vV2ZmpsrLy5Wenh6N7gAAGPSidtNZUVGRioqKovX1AAC4vtObu8QBAOgDgX80N/G2iN5CpQAAIGKosAEA1rp4t7ebeFuQsAEA1uo0Xc1NvC1I2AAAa3ENGwAADChU2AAAawXkU6e6r1PhJN4WJGwAgLUCpqu5ibcFU+IAAFiAChsAYK1Ol1PibmL7GgkbAGAtLyVspsQBALAAFTYAwFoB41PAuLhL3EVsXyNhAwCsxZQ4AAAYUKiwAQDW6tQQdbqoPTsjOJZoI2EDAKxlXF7DNlzDBgAg+riGDQAABhQqbACAtTrNEHUaF9ewLXqXOAkbAGCtgHwKuJgsDsiejM2UOAAAFqDCBgBYy0s3nZGwAQDWcn8NmylxAAAQQVTYAABrdd105mLxD6bEAQCIvoDLV5NylzgAAIgoKmwAgLW8dNMZCRsAYK2AhnjmxSkkbACAtTqNT50uVtxyE9vXuIYNAIAFqLABANbqdHmXeCdT4gAARF/ADFHAxU1nAYtuOmNKHAAAC1BhAwCsxZQ4AAAWCMjdnd6ByA0l6pgSBwDAAlTYACLC5E5wHHPzT485jtn9fyc6jrn+hwccx8AO7l+cYk/dSsIGAFjL/atJ7UnY9owUAAAPo8IGAFiL9bABALCAl6bESdgAAGu5fw7bnoRtz0gBAPAwKmwAgLUCxqeAmxenWLS8JgkbAGCtgMspcZuew7ZnpAAAeBgVNgDAWu6X17SnbiVhAwCs1SmfOl08S+0mtq/Z808LAAA8jAobGMTO3O98oQxJuubhdxzH7PzXZxzHjPANdxzzr3MbHMf89oeJjmNgB6bEAQCwQKfcTWt3Rm4oUWfPPy0AAPAwKmwAgLW8NCUe8ZGWlJTI5/OFtOTk5Eh3AwBAcPEPN80WURnpTTfdpPr6+mA7duxYNLoBAHic+cfymuE2E+b17/Xr1ysjI0OxsbHKysrSvn37Lrv/tm3bNGHCBF111VVKSUnRN77xDTU3NzvqMyoJe+jQoUpOTg6266677pL7tre3q7W1NaQBADBQ7dixQ0uWLNHy5ctVXV2tvLw8FRQUqLa2tsf99+/fr9mzZ2vevHk6fvy4nnvuOR06dEjz58931G9UEvapU6eUmpqqjIwMfe1rX9Pp06cvuW9paakSEhKCLS0tLRpDAgAMQv0xJb5mzRrNmzdP8+fP1/jx47V27VqlpaWprKysx/0PHjyoT3ziE1q8eLEyMjI0adIkPfzwwzp8+LCjfiOesG+//XZt3bpVu3fv1s9//nM1NDQoNzf3kqX/smXL1NLSEmx1dXWRHhIAYJC6uFqXmyap20xve3t7j/11dHToyJEjys/PD9men5+vAwcO9BiTm5urd955R+Xl5TLG6K9//at+85vf6Etf+pKj3zXiCbugoED33Xefbr75Zn3hC1/QSy+9JEl69tlne9zf7/crPj4+pAEA0JfS0tJCZntLS0t73K+pqUmdnZ1KSkoK2Z6UlKSGhp5f6pObm6tt27Zp1qxZGj58uJKTk3Xttdfqpz/9qaMxRv2xrquvvlo333yzTp06Fe2uAAAe0+lyec2LsXV1dSEFo9/vv2yczxd6s5oxptu2i06cOKHFixfrO9/5jr74xS+qvr5ejz32mAoLC7Vx48ZejzXqCbu9vV0nT55UXl5etLsCAHjMR6e1w42X1OsZ3tGjRysmJqZbNd3Y2Nit6r6otLRUd9xxhx577DFJ0mc+8xldffXVysvL0/e//32lpKT0aqwRnxJfunSpqqqqVFNToz/84Q/66le/qtbWVs2ZMyfSXQEA0KeGDx+urKwsVVRUhGyvqKhQbm5ujzHnzp3TkCGh6TYmJkZSV2XeWxGvsN955x19/etfV1NTk6677jpNnDhRBw8eVHp6eqS7Ajzl1JYsxzH/9fmnwurrX4aMCCPK+UIe327IdhxTd/5fHMdIzp53hT0CGqKAi9oznNji4mI9+OCDys7OVk5OjjZs2KDa2loVFhZK6rqZ+t1339XWrVslSdOnT9dDDz2ksrKy4JT4kiVL9LnPfU6pqam97jfiCfvXv/51pL8SAIAedRqfOl1MiYcTO2vWLDU3N2vlypWqr69XZmamysvLg4VpfX19yDPZc+fOVVtbm9atW6dHH31U1157raZOnaof/vCHjvrlXeIAADhUVFSkoqKiHj/bsmVLt22LFi3SokWLXPVJwgYAWCtSN53ZgIQNALCWcblal7Fo8Q8SNgDAWp3yqTPMBTwuxtvCnn9aAADgYVTYAABrBYy769CB3j8G3e9I2AAAawVcXsN2E9vX7BkpAAAeRoUNALBWQD4FXNw45ia2r5GwAQDW6o83nfUXpsQBALAAFTbg1pAYxyF//sUtjmPenLbBcYwUziIe0gtnr3Uc853N/8txTNr/Oew4Rp/t/WIJ/8TiH4OVl246I2EDAKwVkMtXk1p0Dduef1oAAOBhVNgAAGsZl3eJG4sqbBI2AMBarNYFAIAFvHTTmT0jBQDAw6iwAQDWYkocAAALeOnVpEyJAwBgASpsAIC1mBIHAMACXkrYTIkDAGABKmwAgLW8VGGTsIGPGHrjJxzH1K/1O455Myuclbec+x/754YV96lHna9uNeadA45jjOMISYeOhROFQcpLCZspcQAALECFDQCwlpG7Z6nDmuXpJyRsAIC1vDQlTsIGAFjLSwmba9gAAFiAChsAYC0vVdgkbACAtbyUsJkSBwDAAlTYAABrGeOTcVElu4ntayRsAIC1WA8bAAAMKFTYAABreemmMxI2BqWYUSPDist54f85jlk26kRYfTn1+3bnE2I3fuPNsPq6cO5cWHFAX/PSNWymxAEAsAAVNgDAWkyJAwBgAS9NiZOwAQDWMi4rbJsSNtewAQCwABU2AMBaRpIx7uJtQcIGAFgrIJ98vOkMAAAMFFTYAABrcZc4AAAWCBiffB55DpspcQAALECFDQCwljEu7xK36DZxEjYGPN+w4Y5jTv7gk2H19btR/xlWnFMrm252HHP47jTHMYFzDY5jAJt46Ro2U+IAAFiAChsAYC0vVdgkbACAtbhL/DL27t2r6dOnKzU1VT6fTy+88ELI58YYlZSUKDU1VSNGjNCUKVN0/PjxSI0XAICgizeduWm2cJywz549qwkTJmjdunU9fr569WqtWbNG69at06FDh5ScnKxp06apra3N9WABAPAqx1PiBQUFKigo6PEzY4zWrl2r5cuXa+bMmZKkZ599VklJSdq+fbsefvjhbjHt7e1qb28P/tza2up0SAAAj+qqkt1cw47gYKIsoneJ19TUqKGhQfn5+cFtfr9fd955pw4cONBjTGlpqRISEoItLc35oysAAG+6eNOZm2aLiCbshoauZz6TkpJCticlJQU/+7hly5appaUl2Orq6iI5JAAABoWo3CXu84X+i8UY023bRX6/X36/PxrDAAAMckbu1rS2aEY8shV2cnKyJHWrphsbG7tV3QAAuMWUeJgyMjKUnJysioqK4LaOjg5VVVUpNzc3kl0BAOApjqfEz5w5ozfffDP4c01NjY4ePaqRI0fqhhtu0JIlS7Rq1SqNHTtWY8eO1apVq3TVVVfpgQceiOjAAQDw0py444R9+PBh3XXXXcGfi4uLJUlz5szRli1b9O1vf1vnz59XUVGR3n//fd1+++165ZVXFBcXF7lRw1N8N33Kccyb9zwThZH07K0L5xzHHL4n3XHMhfr3HMcAg57bae0wY9evX68f/ehHqq+v10033aS1a9cqLy/vkvu3t7dr5cqV+uUvf6mGhgaNGTNGy5cv1ze/+c1e9+k4YU+ZMkXmMg+u+Xw+lZSUqKSkxOlXAwDgSH8sr7ljxw4tWbJE69ev1x133KFnnnlGBQUFOnHihG644YYeY+6//3799a9/1caNG/WpT31KjY2NunDhgqN+eZc4AAAOrFmzRvPmzdP8+fMlSWvXrtXu3btVVlam0tLSbvu//PLLqqqq0unTpzVy5EhJ0ic+8QnH/bK8JgDAWpG6S7y1tTWkffQNnB/V0dGhI0eOhLwgTJLy8/Mv+YKwXbt2KTs7W6tXr9b111+vcePGaenSpTp//ryj35UKGwBgL+ML+zp0MF7q9pbNFStW9Hhpt6mpSZ2dnY5eEHb69Gnt379fsbGxev7559XU1KSioiL97W9/06ZNm3o9VBI2AMDz6urqFB8fH/z5Si/0cvKCsEAgIJ/Pp23btikhIUFS17T6V7/6Vf3sZz/TiBEjejVGEjYAwFqRuuksPj4+JGFfyujRoxUTE+PoBWEpKSm6/vrrg8laksaPHy9jjN555x2NHTu2V2PlGjYAwF4mAs2B4cOHKysrK+QFYZJUUVFxyReE3XHHHXrvvfd05syZ4LY///nPGjJkiMaMGdPrvknYAAA4UFxcrF/84hfatGmTTp48qUceeUS1tbUqLCyU1LWo1ezZs4P7P/DAAxo1apS+8Y1v6MSJE9q7d68ee+wxffOb3+z1dLjElDgAwGJu3wceTuysWbPU3NyslStXqr6+XpmZmSovL1d6etcLkerr61VbWxvc/5prrlFFRYUWLVqk7OxsjRo1Svfff7++//3vO+qXhA0AsFs/vF60qKhIRUVFPX62ZcuWbts+/elPd5tGd4opcQAALECFDQCwVn9MifcXEjYAwF6s1gVEyZAYxyFvPNR3K729H3D2qkBJmr30Uccx17z7B8cxAHri+0dzE28HrmEDAGABKmwAgL2YEgcAwAIeSthMiQMAYAEqbACAvSK0vKYNSNgAAGtFarUuGzAlDgCABaiwAQD28tBNZyRsAIC9PHQNmylxAAAsQIUNALCWz3Q1N/G2IGEDAOzFNWwgOszETMcxp2aURWEkPYsJYyGAv93kfEGT86NzHMecucFxiEb8Nbzrc8POOP9b7Lod/+04JtDW5jgGCME1bAAAMJBQYQMA7MWUOAAAFvBQwmZKHAAAC1BhAwDs5aEKm4QNALAXd4kDAICBhAobAGAt3nQGAIANPHQNmylxAAAsQMIGAMACTIkDAKzlk8tr2BEbSfSRsNG3fAP7P4/4IbGOY/77oXVRGEl32f+20HFMxbIfhdXXvwwZ4Tjm2PK/O45Z+s1vOY6JefWPjmMwiPFYFwAAGEiosAEA9vLQXeIkbACAvTyUsJkSBwDAAlTYAABr8aYzAABswJQ4AAAYSKiwAQD28lCFTcIGAFjLS9ewmRIHAMACVNgAAHt56NWkJGwAgL24hg1Ex1/+p/PFNcLRHDgfVtzi2umOY268qslxzHMnb3Uc40tz/jfLG393voiHJO18P9txzOrkw45jVm16xnFMSf4sxzGdp047joEduIYNAAAGFCpsAIC9mBIHAMACLqfEbUrYjqfE9+7dq+nTpys1NVU+n08vvPBCyOdz586Vz+cLaRMnTozUeAEA8CTHCfvs2bOaMGGC1q1bd8l97r77btXX1wdbeXm5q0ECANAjE4FmCcdT4gUFBSooKLjsPn6/X8nJyb36vvb2drW3twd/bm1tdTokAIBXeegadlTuEq+srFRiYqLGjRunhx56SI2NjZfct7S0VAkJCcGWlpYWjSEBAGC1iCfsgoICbdu2TXv27NFTTz2lQ4cOaerUqSFV9EctW7ZMLS0twVZXVxfpIQEABqmLz2G7abaI+F3is2b986UGmZmZys7OVnp6ul566SXNnDmz2/5+v19+vz/SwwAAYFCJ+otTUlJSlJ6erlOnTkW7KwAABq2oP4fd3Nysuro6paSkRLsrAIDXeOimM8cJ+8yZM3rzzTeDP9fU1Ojo0aMaOXKkRo4cqZKSEt13331KSUnRW2+9pSeffFKjR4/WvffeG9GBAwDgpXeJO07Yhw8f1l133RX8ubi4WJI0Z84clZWV6dixY9q6das++OADpaSk6K677tKOHTsUFxcXuVFjQIgZNdJxTOk9v3Ic09h5znHM9O8+5jhGkkZt/i/HMX8c5nyBjRvbjzqOCce/rf58WHGBc86P+U3/McdxzPE7nnUcc+E653+X+LgiN7hZlHTdcJywp0yZImMufXR2797takAAAKA73iUOALAX17ABABj4vHQNm/WwAQCwABU2AMBeTIkDADDwMSUOAAAGFBI2AMBe/bQe9vr165WRkaHY2FhlZWVp3759vYr7/e9/r6FDh+qzn/2s4z5J2AAAe/VDwt6xY4eWLFmi5cuXq7q6Wnl5eSooKFBtbe1l41paWjR79mx9/vPhvdCIhA0A8LzW1taQdqkloSVpzZo1mjdvnubPn6/x48dr7dq1SktLU1lZ2WX7ePjhh/XAAw8oJycnrDGSsAEA1orUethpaWlKSEgIttLS0h776+jo0JEjR5Sfnx+yPT8/XwcOHLjkODdv3qy//OUvWrFiRdi/K3eJAwDsFaHHuurq6hQfHx/c7Pf7e9y9qalJnZ2dSkpKCtmelJSkhoaGHmNOnTqlJ554Qvv27dPQoeGnXRI2AMBeEUrY8fHxIQn7Snw+X+jXGNNtmyR1dnbqgQce0He/+12NGzfOxUBJ2HDhw1syHMfcd/V/Oo75j7YbHceM2via45hwmfbOPuvLqc733++zvjoaruqzvoD+Mnr0aMXExHSrphsbG7tV3ZLU1tamw4cPq7q6WgsXLpQkBQIBGWM0dOhQvfLKK5o6dWqv+iZhAwCs1dcvThk+fLiysrJUUVGhe++9N7i9oqJCX/nKV7rtHx8fr2PHjoVsW79+vfbs2aPf/OY3ysjofeFDwgYA2KsfXk1aXFysBx98UNnZ2crJydGGDRtUW1urwsJCSdKyZcv07rvvauvWrRoyZIgyMzND4hMTExUbG9tt+5WQsAEAcGDWrFlqbm7WypUrVV9fr8zMTJWXlys9PV2SVF9ff8VnssNBwgYAWKu/3iVeVFSkoqKiHj/bsmXLZWNLSkpUUlLiuE8SNgDAXh5arYsXpwAAYAEqbACAvTxUYZOwAQDW8v2juYm3BVPiAABYgAobAGAvpsQBABj4+uuxrv5AwgYA2IsKG7gy/2v/z3HM7871fjUc2OWJab/r7yEAgxoJGwBgN4uqZDdI2AAAa3npGjaPdQEAYAEqbACAvbjpDACAgY8pcQAAMKBQYQMA7MWUOAAAAx9T4gAAYEChwgYA2IspcQAALEDCBgBg4PPSNWwSNsIWOHvWccxP357qOObBMQcdx8CliZ9xHDLlqjLHMQfbRziOGfbe+45jLjiOAAYeEjYAwF5MiQMAMPD5jJHPhJ913cT2NR7rAgDAAlTYAAB7MSUOAMDA56W7xJkSBwDAAlTYAAB7MSUOAMDAx5Q4AAAYUKiwAQD2YkocAICBz0tT4iRsAIC9qLCB6GjeNcZxzD2P1TiO+fGCrzqOkaTEnx0IK64vxIy9sc/6mv3s7xzHfHKo84U87n7xW45jxr71B8cxwGBAwgYAWM2maW03SNgAAHsZ09XcxFuCx7oAALCAo4RdWlqq2267TXFxcUpMTNSMGTP0xhtvhOxjjFFJSYlSU1M1YsQITZkyRcePH4/ooAEAkP55l7ibZgtHCbuqqkoLFizQwYMHVVFRoQsXLig/P19nz54N7rN69WqtWbNG69at06FDh5ScnKxp06apra0t4oMHAHiciUCzhKNr2C+//HLIz5s3b1ZiYqKOHDmiyZMnyxijtWvXavny5Zo5c6Yk6dlnn1VSUpK2b9+uhx9+uNt3tre3q729Pfhza2trOL8HAACDmqtr2C0tLZKkkSNHSpJqamrU0NCg/Pz84D5+v1933nmnDhzo+XGZ0tJSJSQkBFtaWpqbIQEAPMQXcN9sEXbCNsaouLhYkyZNUmZmpiSpoaFBkpSUlBSyb1JSUvCzj1u2bJlaWlqCra6uLtwhAQC8hinxK1u4cKFef/117d+/v9tnPp8v5GdjTLdtF/n9fvn9/nCHAQCAJ4RVYS9atEi7du3Sq6++qjFj/vnmquTkZEnqVk03NjZ2q7oBAHCLu8QvwRijhQsXaufOndqzZ48yMjJCPs/IyFBycrIqKiqC2zo6OlRVVaXc3NzIjBgAgIsuvjjFTbOEoynxBQsWaPv27XrxxRcVFxcXrKQTEhI0YsQI+Xw+LVmyRKtWrdLYsWM1duxYrVq1SldddZUeeOCBqPwCAADvYrWuSygrK5MkTZkyJWT75s2bNXfuXEnSt7/9bZ0/f15FRUV6//33dfvtt+uVV15RXFxcRAYMu6WW1zuOOfG/nZ87FU/8yHGMJN0x2fliFEP/dI3jmHNjLjiOqZmxwXFMp+m7W2B/feY6xzHjf/Su4xjnRw4YHBwlbNOLqQOfz6eSkhKVlJSEOyYAAHqH5TUBABj4vDQlzuIfAABYgAobAGAvDy2vScIGAFiLKXEAADCgUGEDAOzFXeIAAAx8TIkDAIABhQobAGCvgOlqbuItQcIGANiLa9gAAAx8Prm8hh2xkUQf17ABALAAFTb6VOebNY5jShbNcxzz4oafOI6RpBOTtjgPmhRWV451hlFFPHdmVFh9fe/ZrzuOuWHtUccxgXPvOI4BQvCmMwAABj4e6wIAAJe0fv16ZWRkKDY2VllZWdq3b98l9925c6emTZum6667TvHx8crJydHu3bsd90nCBgDYy0SgObRjxw4tWbJEy5cvV3V1tfLy8lRQUKDa2toe99+7d6+mTZum8vJyHTlyRHfddZemT5+u6upqR/0yJQ4AsJbPGPlcXIe+GNva2hqy3e/3y+/39xizZs0azZs3T/Pnz5ckrV27Vrt371ZZWZlKS0u77b927dqQn1etWqUXX3xRv/vd73TLLbf0eqxU2AAAz0tLS1NCQkKw9ZR4Jamjo0NHjhxRfn5+yPb8/HwdOHCgV30FAgG1tbVp5MiRjsZIhQ0AsFfgH81NvKS6ujrFx8cHN1+qum5qalJnZ6eSkpJCticlJamhoaFXXT711FM6e/as7r//fkdDJWEDAKwVqSnx+Pj4kIR9xThf6CtXjDHdtvXkV7/6lUpKSvTiiy8qMTHR0VhJ2AAA9NLo0aMVExPTrZpubGzsVnV/3I4dOzRv3jw999xz+sIXvuC4b65hAwDs1cd3iQ8fPlxZWVmqqKgI2V5RUaHc3NxLxv3qV7/S3LlztX37dn3pS19y1uk/UGEDAOzVD286Ky4u1oMPPqjs7Gzl5ORow4YNqq2tVWFhoSRp2bJlevfdd7V161ZJXcl69uzZ+vGPf6yJEycGq/MRI0YoISGh1/2SsAEA1uqPN53NmjVLzc3NWrlyperr65WZmany8nKlp6dLkurr60OeyX7mmWd04cIFLViwQAsWLAhunzNnjrZs2dLrfknYAAA4VFRUpKKioh4/+3gSrqysjEifJGwMeP7yQ45jvvZl5wuGSFLj53o/PXWR+fLfHMdMTHnbcUzlrlsdx9xQ+l+OYyRpzIXePU/6UW6erAHCxuIfAAAMfL5AV3MTbwvuEgcAwAJU2AAAezElDgCABcJccSsk3hJMiQMAYAEqbACAtSL1LnEbkLABAPby0DVspsQBALAAFTYAwF5G7t7aY0+BTcIGANiLa9gAANjAyOU17IiNJOq4hg0AgAWosDEoBY6eCCtu9NEwgjY4D/lLGN2kyfmCHBYVD0B4PHSXOAkbAGCvgCSfy3hLMCUOAIAFqLABANbiLnEAAGzgoWvYTIkDAGABKmwAgL08VGGTsAEA9vJQwmZKHAAAC1BhAwDs5aHnsEnYAABr8VgXAAA24Bo2AAAYSKiwAQD2ChjJ56JKDthTYZOwAQD2YkocAAAMJFTYAACLuaywLVo13lGFXVpaqttuu01xcXFKTEzUjBkz9MYbb4TsM3fuXPl8vpA2ceLEiA4aAABJ/5wSd9Ms4ShhV1VVacGCBTp48KAqKip04cIF5efn6+zZsyH73X333aqvrw+28vLyiA4aAACvcTQl/vLLL4f8vHnzZiUmJurIkSOaPHlycLvf71dycnKvvrO9vV3t7e3Bn1tbW50MCQDgZQEjV9PaFt0l7uqms5aWFknSyJEjQ7ZXVlYqMTFR48aN00MPPaTGxsZLfkdpaakSEhKCLS0tzc2QAABeYgLumyXCTtjGGBUXF2vSpEnKzMwMbi8oKNC2bdu0Z88ePfXUUzp06JCmTp0aUkV/1LJly9TS0hJsdXV14Q4JAIBBK+y7xBcuXKjXX39d+/fvD9k+a9as4J8zMzOVnZ2t9PR0vfTSS5o5c2a37/H7/fL7/eEOAwDgZR56DjushL1o0SLt2rVLe/fu1ZgxYy67b0pKitLT03Xq1KmwBggAwCV56Bq2o4RtjNGiRYv0/PPPq7KyUhkZGVeMaW5uVl1dnVJSUsIeJAAAPfJQhe3oGvaCBQv0y1/+Utu3b1dcXJwaGhrU0NCg8+fPS5LOnDmjpUuX6rXXXtNbb72lyspKTZ8+XaNHj9a9994blV8AAAAvcFRhl5WVSZKmTJkSsn3z5s2aO3euYmJidOzYMW3dulUffPCBUlJSdNddd2nHjh2Ki4uL2KABAJDUNRvuqsKO2EiizvGU+OWMGDFCu3fvdjUgAAB6jSlxAAAwkLD4BwDAXoGAJBcvPwnY8+IUEjYAwF5MiQMAgIGEChsAYC8PVdgkbACAvTz0pjOmxAEAsAAVNgDAWsYEZFwskekmtq+RsAEA9jLG3bQ217ABAOgDxuU1bIsSNtewAQCwABU2AMBegYDkc3EdmmvYAAD0AabEAQDAQEKFDQCwlgkEZFxMifNYFwAAfYEpcQAAMJBQYQMA7BUwks8bFTYJGwBgL2MkuXmsy56EzZQ4AAAWoMIGAFjLBIyMiylxY1GFTcIGANjLBORuStyex7qYEgcAWMsEjOsWjvXr1ysjI0OxsbHKysrSvn37Lrt/VVWVsrKyFBsbqxtvvFFPP/204z5J2AAAOLBjxw4tWbJEy5cvV3V1tfLy8lRQUKDa2toe96+pqdE999yjvLw8VVdX68knn9TixYv129/+1lG/PjPAJvBbWlp07bXXapLu0VAN6+/hAAAcuqC/a7/K9cEHHyghISEqfbS2tiohIcF1rrg41rq6OsXHxwe3+/1++f3+HmNuv/123XrrrSorKwtuGz9+vGbMmKHS0tJu+z/++OPatWuXTp48GdxWWFioP/3pT3rttdd6P1gzwNTV1V18bQ2NRqPRLG51dXVRyxXnz583ycnJERnnNddc023bihUreuy3vb3dxMTEmJ07d4ZsX7x4sZk8eXKPMXl5eWbx4sUh23bu3GmGDh1qOjo6ev07D7ibzlJTU1VXV6e4uDj5fL6Qz1pbW5WWltbtX0Jew3HownHownHownHoMhCOgzFGbW1tSk1NjVofsbGxqqmpUUdHh+vvMsZ0yzeXqq6bmprU2dmppKSkkO1JSUlqaGjoMaahoaHH/S9cuKCmpialpKT0apwDLmEPGTJEY8aMuew+8fHxnv4P8iKOQxeOQxeOQxeOQ5f+Pg7Rmgr/qNjYWMXGxka9n558PMH3lPSvtH9P2y+Hm84AAOil0aNHKyYmpls13djY2K2Kvig5ObnH/YcOHapRo0b1um8SNgAAvTR8+HBlZWWpoqIiZHtFRYVyc3N7jMnJyem2/yuvvKLs7GwNG9b7G+asSth+v18rVqy45LUFr+A4dOE4dOE4dOE4dOE4RF9xcbF+8YtfaNOmTTp58qQeeeQR1dbWqrCwUJK0bNkyzZ49O7h/YWGh3n77bRUXF+vkyZPatGmTNm7cqKVLlzrqd8A91gUAwEC3fv16rV69WvX19crMzNS///u/a/LkyZKkuXPn6q233lJlZWVw/6qqKj3yyCM6fvy4UlNT9fjjjwcTfG+RsAEAsIBVU+IAAHgVCRsAAAuQsAEAsAAJGwAAC1iVsJ0uZzbYlJSUyOfzhbTk5OT+HlbU7d27V9OnT1dqaqp8Pp9eeOGFkM+NMSopKVFqaqpGjBihKVOm6Pjx4/0z2Ci60nGYO3dut/Nj4sSJ/TPYKCktLdVtt92muLg4JSYmasaMGXrjjTdC9vHC+dCb4+CF88FrrEnYTpczG6xuuukm1dfXB9uxY8f6e0hRd/bsWU2YMEHr1q3r8fPVq1drzZo1WrdunQ4dOqTk5GRNmzZNbW1tfTzS6LrScZCku+++O+T8KC8v78MRRl9VVZUWLFiggwcPqqKiQhcuXFB+fr7Onj0b3McL50NvjoM0+M8Hz+n1MiH97HOf+5wpLCwM2fbpT3/aPPHEE/00or63YsUKM2HChP4eRr+SZJ5//vngz4FAwCQnJ5sf/OAHwW0ffvihSUhIME8//XQ/jLBvfPw4GGPMnDlzzFe+8pV+GU9/aWxsNJJMVVWVMca758PHj4Mx3jwfBjsrKuyOjg4dOXJE+fn5Idvz8/N14MCBfhpV/zh16pRSU1OVkZGhr33tazp9+nR/D6lf1dTUqKGhIeTc8Pv9uvPOOz13bkhSZWWlEhMTNW7cOD300ENqbGzs7yFFVUtLiyRp5MiRkrx7Pnz8OFzktfNhsLMiYYeznNlgdPvtt2vr1q3avXu3fv7zn6uhoUG5ublqbm7u76H1m4v//3v93JCkgoICbdu2TXv27NFTTz2lQ4cOaerUqWpvb+/voUWFMUbFxcWaNGmSMjMzJXnzfOjpOEjeOx+8YMAtr3k5TpczG2wKCgqCf7755puVk5OjT37yk3r22WdVXFzcjyPrf14/NyRp1qxZwT9nZmYqOztb6enpeumllzRz5sx+HFl0LFy4UK+//rr279/f7TMvnQ+XOg5eOx+8wIoKO5zlzLzg6quv1s0336xTp07191D6zcW75Dk3uktJSVF6evqgPD8WLVqkXbt26dVXX9WYMWOC2712PlzqOPRkMJ8PXmFFwg5nOTMvaG9v18mTJ5WSktLfQ+k3GRkZSk5ODjk3Ojo6VFVV5elzQ5Kam5tVV1c3qM4PY4wWLlyonTt3as+ePcrIyAj53Cvnw5WOQ08G4/ngOf14w5sjv/71r82wYcPMxo0bzYkTJ8ySJUvM1Vdfbd56663+HlqfefTRR01lZaU5ffq0OXjwoPnyl79s4uLiBv0xaGtrM9XV1aa6utpIMmvWrDHV1dXm7bffNsYY84Mf/MAkJCSYnTt3mmPHjpmvf/3rJiUlxbS2tvbzyCPrcsehra3NPProo+bAgQOmpqbGvPrqqyYnJ8dcf/31g+o4fOtb3zIJCQmmsrLS1NfXB9u5c+eC+3jhfLjScfDK+eA11iRsY4z52c9+ZtLT083w4cPNrbfeGvIIgxfMmjXLpKSkmGHDhpnU1FQzc+ZMc/z48f4eVtS9+uqrRlK3NmfOHGNM16M8K1asMMnJycbv95vJkyebY8eO9e+go+Byx+HcuXMmPz/fXHfddWbYsGHmhhtuMHPmzDG1tbX9PeyI6un3l2Q2b94c3McL58OVjoNXzgevYXlNAAAsYMU1bAAAvI6EDQCABUjYAABYgIQNAIAFSNgAAFiAhA0AgAVI2AAAWICEDQCABUjYAABYgIQNAIAFSNgAAFjg/wNHBpJVWdGFFwAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "number = 457\n",
    "plt.figure()\n",
    "plt.imshow(test_inputs[:, number].reshape(28, 28))\n",
    "plt.colorbar()\n",
    "plt.grid(False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[6] tf.Tensor(\n",
      "[[1.7879098e-37]\n",
      " [0.0000000e+00]\n",
      " [9.5889400e-34]\n",
      " [2.9762484e-38]\n",
      " [0.0000000e+00]\n",
      " [3.8614474e-18]\n",
      " [1.0000000e+00]\n",
      " [0.0000000e+00]\n",
      " [0.0000000e+00]\n",
      " [0.0000000e+00]], shape=(10, 1), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "A_output , outputs = brain_one.predict(test_inputs[:, number].reshape(-1, 1))\n",
    "print(A_output , outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recognized Digits: [array([1]), array([5]), array([7]), array([1]), array([2]), array([3]), array([6]), array([1]), array([0])]\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "def preprocess_page(image_path):\n",
    "    # Load the image in grayscale\n",
    "    img = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "    # Apply Gaussian Blur to remove noise\n",
    "    img_blur = cv2.GaussianBlur(img, (5, 5), 0)\n",
    "\n",
    "    # Apply Adaptive Thresholding to detect digits clearly\n",
    "    img_thresh = cv2.adaptiveThreshold(img_blur, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C, cv2.THRESH_BINARY_INV, 11, 2)\n",
    "\n",
    "    return img_thresh\n",
    "\n",
    "def extract_and_segment_digits(image):\n",
    "    # Find contours (digit outlines)\n",
    "    contours, _ = cv2.findContours(image, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "    digit_images = []\n",
    "    bounding_boxes = []\n",
    "\n",
    "    for contour in contours:\n",
    "        # Get bounding box for each detected digit\n",
    "        x, y, w, h = cv2.boundingRect(contour)\n",
    "        bounding_boxes.append((x, y, w, h))\n",
    "\n",
    "    # Sort bounding boxes from left to right (important for multi-digit numbers)\n",
    "    bounding_boxes = sorted(bounding_boxes, key=lambda b: b[0])\n",
    "\n",
    "    for x, y, w, h in bounding_boxes:\n",
    "        # Extract the digit\n",
    "        digit = image[y:y+h, x:x+w]\n",
    "\n",
    "\n",
    "        padding = 10\n",
    "\n",
    "        # Make the digit square by adding padding\n",
    "        size = max(w, h)  # Get the max dimension\n",
    "        pad_x = (size - w) // 1 + padding # Padding for width\n",
    "        pad_y = (size - h) // 1 + padding # Padding for height\n",
    "\n",
    "        digit_padded = cv2.copyMakeBorder(digit, pad_y, pad_y, pad_x, pad_x, cv2.BORDER_CONSTANT, value=0)\n",
    "\n",
    "        # Resize to 28x28 pixels\n",
    "        digit_resized = cv2.resize(digit_padded, (28, 28))\n",
    "\n",
    "        # Normalize and reshape for model input\n",
    "        digit_resized = digit_resized / 255.0\n",
    "        digit_resized = digit_resized.reshape(784, 1)  # Convert to (784,1) shape for neural network\n",
    "\n",
    "        digit_images.append(digit_resized)\n",
    "\n",
    "    return digit_images\n",
    "\n",
    "# Load and preprocess the page image\n",
    "image_path = \"/Users/sriramkurnella/AI/My_Work/Numbers.png\"  # Replace with your image path\n",
    "preprocessed_image = preprocess_page(image_path)\n",
    "\n",
    "# Extract and segment digits\n",
    "digit_images = extract_and_segment_digits(preprocessed_image)\n",
    "\n",
    "# Predict each digit using trained model\n",
    "predicted_digits = [brain_one.predict(digit) for digit in digit_images]\n",
    "\n",
    "print(\"Recognized Digits:\", predicted_digits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "plt.figure()\n",
    "plt.imshow(digit_images[2].reshape(28, 28))\n",
    "plt.colorbar()\n",
    "plt.grid(False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[7]\n"
     ]
    }
   ],
   "source": [
    "A_output = brain_one.predict(digit_images[2].reshape(-1, 1))\n",
    "print(A_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy =  8.5\n"
     ]
    }
   ],
   "source": [
    "A_output_pred = 0\n",
    "for i in range(1000):\n",
    "    if np.argmax(brain_one.predict(test_inputs[:, i].reshape(-1, 1))) == np.argmax(test_outputs[:, i]):\n",
    "        A_output_pred += 1\n",
    "\n",
    "print(\"Accuracy = \", (A_output_pred / 1000) * 100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  940,  8806,  6400,   536, 25300, 10948,  4402,  2668])"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(np.bincount(A_output))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframe = pd.read_csv(\"/Users/sriramkurnella/AI/Machine Learning A-Z (Codes and Datasets)/train.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 42000 entries, 0 to 41999\n",
      "Columns: 785 entries, label to pixel783\n",
      "dtypes: int64(785)\n",
      "memory usage: 251.5 MB\n"
     ]
    }
   ],
   "source": [
    "dataframe.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_inputs = np.array(dataframe.iloc[0:40000 , 1:])\n",
    "train_output = np.array(dataframe.iloc[0:40000, 1]).reshape(1, -1)  # Shape (1, 40000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Loss: 0.6562216877937317\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[234], line 12\u001b[0m\n\u001b[1;32m     10\u001b[0m epochs \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1500\u001b[39m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(epochs):\n\u001b[0;32m---> 12\u001b[0m     loss \u001b[38;5;241m=\u001b[39m brain_one\u001b[38;5;241m.\u001b[39mback_propagation(learning_rate\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.01\u001b[39m)\n\u001b[1;32m     13\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m epoch \u001b[38;5;241m%\u001b[39m \u001b[38;5;241m100\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m     14\u001b[0m         \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEpoch \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepoch\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, Loss: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mloss\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[0;32mIn[82], line 47\u001b[0m, in \u001b[0;36mNeuralNetwork.back_propagation\u001b[0;34m(self, learning_rate)\u001b[0m\n\u001b[1;32m     44\u001b[0m     loss \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mreduce_mean(tf\u001b[38;5;241m.\u001b[39msquare(output \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moutput))  \u001b[38;5;66;03m# Mean Squared Error Loss\u001b[39;00m\n\u001b[1;32m     46\u001b[0m \u001b[38;5;66;03m# Compute gradients\u001b[39;00m\n\u001b[0;32m---> 47\u001b[0m gradients \u001b[38;5;241m=\u001b[39m tape\u001b[38;5;241m.\u001b[39mgradient(loss, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mweights \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbiases)\n\u001b[1;32m     49\u001b[0m \u001b[38;5;66;03m# Update weights and biases using gradient descent\u001b[39;00m\n\u001b[1;32m     50\u001b[0m optimizer \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39moptimizers\u001b[38;5;241m.\u001b[39mAdam(learning_rate)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/site-packages/tensorflow/python/eager/backprop.py:1066\u001b[0m, in \u001b[0;36mGradientTape.gradient\u001b[0;34m(self, target, sources, output_gradients, unconnected_gradients)\u001b[0m\n\u001b[1;32m   1060\u001b[0m   output_gradients \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m   1061\u001b[0m       composite_tensor_gradient\u001b[38;5;241m.\u001b[39mget_flat_tensors_for_gradients(\n\u001b[1;32m   1062\u001b[0m           output_gradients))\n\u001b[1;32m   1063\u001b[0m   output_gradients \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01mif\u001b[39;00m x \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m ops\u001b[38;5;241m.\u001b[39mconvert_to_tensor(x)\n\u001b[1;32m   1064\u001b[0m                       \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m output_gradients]\n\u001b[0;32m-> 1066\u001b[0m flat_grad \u001b[38;5;241m=\u001b[39m imperative_grad\u001b[38;5;241m.\u001b[39mimperative_grad(\n\u001b[1;32m   1067\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_tape,\n\u001b[1;32m   1068\u001b[0m     flat_targets,\n\u001b[1;32m   1069\u001b[0m     flat_sources,\n\u001b[1;32m   1070\u001b[0m     output_gradients\u001b[38;5;241m=\u001b[39moutput_gradients,\n\u001b[1;32m   1071\u001b[0m     sources_raw\u001b[38;5;241m=\u001b[39mflat_sources_raw,\n\u001b[1;32m   1072\u001b[0m     unconnected_gradients\u001b[38;5;241m=\u001b[39munconnected_gradients)\n\u001b[1;32m   1074\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_persistent:\n\u001b[1;32m   1075\u001b[0m   \u001b[38;5;66;03m# Keep track of watched variables before setting tape to None\u001b[39;00m\n\u001b[1;32m   1076\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_watched_variables \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_tape\u001b[38;5;241m.\u001b[39mwatched_variables()\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/site-packages/tensorflow/python/eager/imperative_grad.py:67\u001b[0m, in \u001b[0;36mimperative_grad\u001b[0;34m(tape, target, sources, output_gradients, sources_raw, unconnected_gradients)\u001b[0m\n\u001b[1;32m     63\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m:\n\u001b[1;32m     64\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m     65\u001b[0m       \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUnknown value for unconnected_gradients: \u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m unconnected_gradients)\n\u001b[0;32m---> 67\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m pywrap_tfe\u001b[38;5;241m.\u001b[39mTFE_Py_TapeGradient(\n\u001b[1;32m     68\u001b[0m     tape\u001b[38;5;241m.\u001b[39m_tape,  \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n\u001b[1;32m     69\u001b[0m     target,\n\u001b[1;32m     70\u001b[0m     sources,\n\u001b[1;32m     71\u001b[0m     output_gradients,\n\u001b[1;32m     72\u001b[0m     sources_raw,\n\u001b[1;32m     73\u001b[0m     compat\u001b[38;5;241m.\u001b[39mas_str(unconnected_gradients\u001b[38;5;241m.\u001b[39mvalue))\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/site-packages/tensorflow/python/eager/backprop.py:118\u001b[0m, in \u001b[0;36m_gradient_function\u001b[0;34m(op_name, attr_tuple, num_inputs, inputs, outputs, out_grads, skip_input_indices, forward_pass_name_scope)\u001b[0m\n\u001b[1;32m    109\u001b[0m   \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_get_control_flow_context\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    110\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mNotImplementedError\u001b[39;00m(\n\u001b[1;32m    111\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtf.GradientTape.gradients() does not support graph control flow \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    112\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moperations like tf.cond or tf.while at this time. Use tf.gradients() \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    113\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minstead. If you need this feature, please file a feature request at \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    114\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhttps://github.com/tensorflow/tensorflow/issues/new\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    115\u001b[0m     )\n\u001b[0;32m--> 118\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_gradient_function\u001b[39m(op_name, attr_tuple, num_inputs, inputs, outputs,\n\u001b[1;32m    119\u001b[0m                        out_grads, skip_input_indices, forward_pass_name_scope):\n\u001b[1;32m    120\u001b[0m \u001b[38;5;250m  \u001b[39m\u001b[38;5;124;03m\"\"\"Calls the gradient function of the op.\u001b[39;00m\n\u001b[1;32m    121\u001b[0m \n\u001b[1;32m    122\u001b[0m \u001b[38;5;124;03m  Args:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    134\u001b[0m \u001b[38;5;124;03m    The gradients with respect to the inputs of the function, as a list.\u001b[39;00m\n\u001b[1;32m    135\u001b[0m \u001b[38;5;124;03m  \"\"\"\u001b[39;00m\n\u001b[1;32m    136\u001b[0m   mock_op \u001b[38;5;241m=\u001b[39m _MockOp(attr_tuple, inputs, outputs, op_name, skip_input_indices)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Example Dataset\n",
    "train_inputs = np.random.rand(784, 10000).astype('float32')  # Shape (features, samples)\n",
    "train_outputs = np.random.rand(1, 10000).astype('float32')  # Shape (1, samples)\n",
    "\n",
    "# Initialize Model\n",
    "hidden_layer_dimensions = [40, 40]\n",
    "brain_one = NeuralNetwork(hidden_layer_dimensions, train_outputs, train_inputs)\n",
    "\n",
    "# Train the Model\n",
    "epochs = 1500\n",
    "for epoch in range(epochs):\n",
    "    loss = brain_one.back_propagation(learning_rate=0.01)\n",
    "    if epoch % 100 == 0:\n",
    "        print(f\"Epoch {epoch}, Loss: {loss}\")\n",
    "\n",
    "# Predict\n",
    "predicted_output, _ = brain_one.forward_propagation()\n",
    "print(predicted_output.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "cannot reshape array of size 10000 into shape (28,28)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[87], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m plt\u001b[38;5;241m.\u001b[39mfigure()\n\u001b[0;32m----> 2\u001b[0m plt\u001b[38;5;241m.\u001b[39mimshow(predicted_output\u001b[38;5;241m.\u001b[39mnumpy()\u001b[38;5;241m.\u001b[39mreshape(\u001b[38;5;241m28\u001b[39m, \u001b[38;5;241m28\u001b[39m))\n\u001b[1;32m      3\u001b[0m plt\u001b[38;5;241m.\u001b[39mcolorbar()\n\u001b[1;32m      4\u001b[0m plt\u001b[38;5;241m.\u001b[39mgrid(\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "\u001b[0;31mValueError\u001b[0m: cannot reshape array of size 10000 into shape (28,28)"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure()\n",
    "plt.imshow(predicted_output.numpy().reshape(28, 28))\n",
    "plt.colorbar()\n",
    "plt.grid(False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[nan nan nan ... nan nan nan]]\n"
     ]
    }
   ],
   "source": [
    "train_inputs = np.array(dataframe.iloc[0:40000, 1:]).T  # Shape (784, 40000)\n",
    "train_outputs = np.array(dataframe.iloc[0:40000, 0]).reshape(1, -1)  # Shape (1, 40000)\n",
    "\n",
    "# Normalize Output\n",
    "train_output = (train_output - np.min(train_output)) / (np.max(train_output) - np.min(train_output))\n",
    "\n",
    "# Initialize and Train\n",
    "hidden_layer_dimensions = [40, 40]\n",
    "brain_one = NeuralNetwork(hidden_layer_dimensions, train_output, train_inputs)\n",
    "\n",
    "# Train the model with more iterations\n",
    "for _ in range(1000):  # More iterations for stability\n",
    "    brain_one.back_propagation(learning_rate=0.01)\n",
    "\n",
    "# Predict\n",
    "predicted_output, _ = brain_one.forward_propagation()\n",
    "\n",
    "# Rescale Output\n",
    "predicted_output = predicted_output * (np.max(train_output) - np.min(train_output)) + np.min(train_output)\n",
    "\n",
    "print(predicted_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       ...,\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0]])"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available: 0\n"
     ]
    }
   ],
   "source": [
    "print(\"Num GPUs Available:\", len(tf.config.experimental.list_physical_devices('GPU')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>pixel0</th>\n",
       "      <th>pixel1</th>\n",
       "      <th>pixel2</th>\n",
       "      <th>pixel3</th>\n",
       "      <th>pixel4</th>\n",
       "      <th>pixel5</th>\n",
       "      <th>pixel6</th>\n",
       "      <th>pixel7</th>\n",
       "      <th>pixel8</th>\n",
       "      <th>...</th>\n",
       "      <th>pixel774</th>\n",
       "      <th>pixel775</th>\n",
       "      <th>pixel776</th>\n",
       "      <th>pixel777</th>\n",
       "      <th>pixel778</th>\n",
       "      <th>pixel779</th>\n",
       "      <th>pixel780</th>\n",
       "      <th>pixel781</th>\n",
       "      <th>pixel782</th>\n",
       "      <th>pixel783</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 785 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   label  pixel0  pixel1  pixel2  pixel3  pixel4  pixel5  pixel6  pixel7  \\\n",
       "0      1       0       0       0       0       0       0       0       0   \n",
       "1      0       0       0       0       0       0       0       0       0   \n",
       "2      1       0       0       0       0       0       0       0       0   \n",
       "3      4       0       0       0       0       0       0       0       0   \n",
       "4      0       0       0       0       0       0       0       0       0   \n",
       "\n",
       "   pixel8  ...  pixel774  pixel775  pixel776  pixel777  pixel778  pixel779  \\\n",
       "0       0  ...         0         0         0         0         0         0   \n",
       "1       0  ...         0         0         0         0         0         0   \n",
       "2       0  ...         0         0         0         0         0         0   \n",
       "3       0  ...         0         0         0         0         0         0   \n",
       "4       0  ...         0         0         0         0         0         0   \n",
       "\n",
       "   pixel780  pixel781  pixel782  pixel783  \n",
       "0         0         0         0         0  \n",
       "1         0         0         0         0  \n",
       "2         0         0         0         0  \n",
       "3         0         0         0         0  \n",
       "4         0         0         0         0  \n",
       "\n",
       "[5 rows x 785 columns]"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataframe.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'dataframe' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[11], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m plt\u001b[38;5;241m.\u001b[39mfigure()\n\u001b[0;32m----> 2\u001b[0m plt\u001b[38;5;241m.\u001b[39mimshow(dataframe\u001b[38;5;241m.\u001b[39miloc[\u001b[38;5;241m20\u001b[39m, \u001b[38;5;241m1\u001b[39m:]\u001b[38;5;241m.\u001b[39mvalues\u001b[38;5;241m.\u001b[39mreshape(\u001b[38;5;241m28\u001b[39m, \u001b[38;5;241m28\u001b[39m))\n\u001b[1;32m      3\u001b[0m plt\u001b[38;5;241m.\u001b[39mcolorbar()\n\u001b[1;32m      4\u001b[0m plt\u001b[38;5;241m.\u001b[39mgrid(\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'dataframe' is not defined"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure()\n",
    "plt.imshow(dataframe.iloc[20, 1:].values.reshape(28, 28))\n",
    "plt.colorbar()\n",
    "plt.grid(False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 2.91707685  4.99443784  6.92111515  8.87502386 10.85411436 12.85789359\n",
      "  14.88160912 16.90108584 18.87256106 20.7437251 ]]\n"
     ]
    }
   ],
   "source": [
    "train_inputs = np.array([\n",
    "    [1, 2, 3, 4, 5, 6, 7, 8, 9, 10],\n",
    "    [2, 3, 4, 5, 6, 7, 8, 9, 10, 11]\n",
    "])\n",
    "\n",
    "train_output = np.array([\n",
    "    [3, 5, 7, 9, 11, 13, 15, 17, 19, 21]\n",
    "])\n",
    "\n",
    "# Normalize Output\n",
    "train_output = (train_output - np.min(train_output)) / (np.max(train_output) - np.min(train_output))\n",
    "\n",
    "# Initialize and Train\n",
    "hidden_layer_dimensions = [16 , 16]\n",
    "brain_one = NeuralNetwork(hidden_layer_dimensions, train_output, train_inputs)\n",
    "\n",
    "# Train the model with more iterations\n",
    "for _ in range(50000):  # More iterations for stability\n",
    "    brain_one.back_propagation(learning_rate=0.01)\n",
    "\n",
    "# Predict\n",
    "predicted_output, _ = brain_one.forward_propagation()\n",
    "\n",
    "# Rescale Output\n",
    "predicted_output = predicted_output * (21 - 3) + 3  # Reverse normalization\n",
    "\n",
    "print(predicted_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_inputs = np.array([[2, 3], [3, 4]]).T\n",
    "train_output = np.array([[4, 5]])\n",
    "hidden_layer_dimensions = [16, 16]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "brain_one = NeuralNetwork(hidden_layer_dimensions, np.array(train_output), np.array(train_inputs))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[2, 3],\n",
       "        [3, 4]]),\n",
       " array([[ 0.9935049 ,  0.99923343],\n",
       "        [ 0.98643462,  0.99822211],\n",
       "        [-0.22385969, -0.20221265],\n",
       "        [ 0.14474264,  0.5108657 ],\n",
       "        [ 0.99996711,  0.99999957],\n",
       "        [-0.92956045, -0.97888797],\n",
       "        [ 0.99956256,  0.99998519],\n",
       "        [-0.2631077 , -0.49650049],\n",
       "        [-0.84680119, -0.91079968],\n",
       "        [ 0.8788682 ,  0.97526838],\n",
       "        [-0.99883515, -0.99989209],\n",
       "        [ 0.04892827, -0.23563968],\n",
       "        [-0.93697532, -0.98449775],\n",
       "        [ 0.98288935,  0.99816361],\n",
       "        [-0.97788286, -0.9973085 ],\n",
       "        [-0.99999944, -1.        ]]),\n",
       " array([[-0.59531821, -0.6033032 ],\n",
       "        [-0.77449219, -0.71213309],\n",
       "        [-0.39040863, -0.54893732],\n",
       "        [-0.04530551,  0.00945575],\n",
       "        [ 0.83577996,  0.89541987],\n",
       "        [ 0.76385389,  0.84842869],\n",
       "        [-0.49773595, -0.65963343],\n",
       "        [ 0.56162955,  0.64477405],\n",
       "        [-0.88076161, -0.90856908],\n",
       "        [-0.25821393, -0.35083679],\n",
       "        [-0.60866045, -0.64493314],\n",
       "        [ 0.46009696,  0.59675166],\n",
       "        [ 0.49484575,  0.5322019 ],\n",
       "        [-0.59513087, -0.73358916],\n",
       "        [ 0.40495168,  0.36961552],\n",
       "        [ 0.57048786,  0.61097945]]),\n",
       " array([[0.7600068 , 0.74269814]])]"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cal_ouputs , Activations = brain_one.forward_propagation()\n",
    "\n",
    "Activations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.7600068 , 0.74269814]])"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cal_ouputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "786-i\n",
    "128 + 15 - h\n",
    "10 - o"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
