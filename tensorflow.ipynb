{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import cv2\n",
    "\n",
    "from IPython.display import clear_output\n",
    "import sys\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeuralNetwork:\n",
    "    def __init__(self, hidden_layers_dimensions, outputs, inputs):\n",
    "        self.input_layer_dimension = inputs.shape[0]\n",
    "        self.hidden_layers_dimensions = hidden_layers_dimensions\n",
    "        self.output_layer_dimension = outputs.shape[0]\n",
    "        self.input_layer = tf.convert_to_tensor(inputs, dtype=tf.float32)\n",
    "        self.output = tf.convert_to_tensor(outputs, dtype=tf.float32)\n",
    "\n",
    "        self.weights = []\n",
    "        self.biases = []\n",
    "\n",
    "        # Input to first hidden layer\n",
    "        self.weights.append(tf.Variable(tf.random.normal([self.hidden_layers_dimensions[0], self.input_layer_dimension], stddev=0.1, dtype=tf.float32)))\n",
    "        self.biases.append(tf.Variable(tf.zeros([self.hidden_layers_dimensions[0], 1], dtype=tf.float32)))\n",
    "\n",
    "        # Hidden layers\n",
    "        for i in range(1, len(self.hidden_layers_dimensions)):\n",
    "            self.weights.append(tf.Variable(tf.random.normal([self.hidden_layers_dimensions[i], self.hidden_layers_dimensions[i - 1]], stddev=tf.sqrt(1.0 / self.hidden_layers_dimensions[i - 1]), dtype=tf.float32)))\n",
    "            self.biases.append(tf.Variable(tf.zeros([self.hidden_layers_dimensions[i], 1], dtype=tf.float32)))\n",
    "\n",
    "        self.weights.append(tf.Variable(tf.random.normal([self.output_layer_dimension, self.hidden_layers_dimensions[-1]], stddev=tf.sqrt(1.0 / self.hidden_layers_dimensions[-1]), dtype=tf.float32)))\n",
    "        self.biases.append(tf.Variable(tf.zeros([self.output_layer_dimension, 1], dtype=tf.float32)))\n",
    "\n",
    "    def forward_pass(self):\n",
    "        self.hidden_layers_outputs = []\n",
    "        self.hidden_layers_outputs.append(tf.nn.relu(tf.add(tf.matmul(self.weights[0], self.input_layer), self.biases[0])))\n",
    "        for i in range(1, len(self.hidden_layers_dimensions)):\n",
    "            self.hidden_layers_outputs.append(tf.nn.relu(tf.add(tf.matmul(self.weights[i], self.hidden_layers_outputs[i - 1]), self.biases[i])))\n",
    "        self.output_layer_output = tf.add(tf.matmul(self.weights[-1], self.hidden_layers_outputs[-1]), self.biases[-1])\n",
    "        return self.output_layer_output\n",
    "    \n",
    "    def backward_pass(self):\n",
    "        self.output_layer_error = tf.subtract(self.output_layer_output, self.output)\n",
    "        self.output_layer_delta = tf.multiply(self.output_layer_error, tf.nn.relu(self.output_layer_output))\n",
    "        self.hidden_layers_errors = []\n",
    "        self.hidden_layers_deltas = []\n",
    "        for i in range(len(self.hidden_layers_dimensions) - 1, -1, -1):\n",
    "            self.hidden_layers_errors.append(tf.matmul(tf.transpose(self.weights[i + 1]), self.output_layer_delta))\n",
    "            self.hidden_layers_deltas.append(tf.multiply(self.hidden_layers_errors[len(self.hidden_layers_errors) - 1], tf.nn.relu(self.hidden_layers_outputs[i])))\n",
    "        self.hidden_layers_errors.reverse()\n",
    "        self.hidden_layers_deltas.reverse()\n",
    "        return self.hidden_layers_deltas\n",
    "    \n",
    "    def triann(self, epochs, learning_rate):\n",
    "        for epoch in range(epochs):\n",
    "            self.forward_pass()\n",
    "            self.backward_pass()\n",
    "            for i in range(len(self.hidden_layers_dimensions)):\n",
    "                self.weights[i] = tf.add(self.weights[i], tf.multiply(learning_rate, tf.matmul(self.hidden_layers_deltas[i], tf.transpose(self.hidden_layers_outputs[i]))))\n",
    "                self.biases[i] = tf.add(self.biases[i], tf.multiply(learning_rate, tf.reduce_sum(self.hidden_layers_deltas[i], axis=1, keepdims=True)))\n",
    "            self.weights[-1] = tf.add(self.weights[-1], tf.multiply(learning_rate, tf.matmul(self.output_layer_delta, tf.transpose(self.hidden_layers_outputs[-1])))\n",
    "            self.biases[-1] = tf.add(self.biases[-1], tf.multiply(learning_rate, tf.reduce_\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"OMP_NUM_THREADS\"] = \"4\"  # Adjust based on CPU cores\n",
    "os.environ[\"TF_NUM_INTEROP_THREADS\"] = \"4\"\n",
    "\n",
    "import tensorflow as tf\n",
    "tf.keras.mixed_precision.set_global_policy('mixed_float16')\n",
    "class NeuralNetwork:\n",
    "    def __init__(self, input_size, output_size, hidden_layers, network_type=\"classifier\"):\n",
    "        self.input_size = input_size\n",
    "        self.output_size = output_size\n",
    "        self.hidden_layers = hidden_layers\n",
    "        self.network_type = network_type\n",
    "\n",
    "        tf.config.threading.set_intra_op_parallelism_threads(0)\n",
    "        tf.config.threading.set_inter_op_parallelism_threads(0)\n",
    "        tf.keras.mixed_precision.set_global_policy('mixed_float16')\n",
    "        \n",
    "        self.weights, self.biases = self.initialize_weights()\n",
    "\n",
    "    def initialize_weights(self):\n",
    "        weights = {}\n",
    "        biases = {}\n",
    "        prev_layer_size = self.input_size\n",
    "        \n",
    "        for i, layer_size in enumerate(self.hidden_layers):\n",
    "            weights[f\"W{i+1}\"] = tf.Variable(tf.random.normal([prev_layer_size, layer_size], stddev=0.1, dtype=tf.float16))\n",
    "            biases[f\"b{i+1}\"] = tf.Variable(tf.zeros([layer_size], dtype=tf.float16))\n",
    "            prev_layer_size = layer_size\n",
    "\n",
    "        weights[\"W_out\"] = tf.Variable(tf.random.normal([prev_layer_size, self.output_size], stddev=0.1, dtype=tf.float16))\n",
    "        biases[\"b_out\"] = tf.Variable(tf.zeros([self.output_size], dtype=tf.float16))\n",
    "\n",
    "        return weights, biases\n",
    "\n",
    "    @tf.function(jit_compile=True)\n",
    "    def build_model(self, inputs):\n",
    "        layer = inputs\n",
    "        for i in range(len(self.hidden_layers)):\n",
    "            layer = tf.nn.relu(tf.add(tf.matmul(layer, self.weights[f\"W{i+1}\"],), self.biases[f\"b{i+1}\"]))\n",
    "        outputs = tf.add(tf.matmul(layer, self.weights[\"W_out\"]), self.biases[\"b_out\"])\n",
    "        return tf.nn.softmax(outputs) if self.network_type == \"classifier\" else outputs\n",
    "\n",
    "    def train(self, X_train, y_train, epochs=100, batch_size=32, learning_rate=0.001, verbose=True):\n",
    "        dataset = tf.data.Dataset.from_tensor_slices((X_train, y_train)).batch(batch_size).prefetch(tf.data.experimental.AUTOTUNE)\n",
    "        optimizer = tf.keras.optimizers.Adam(learning_rate=learning_rate)\n",
    "\n",
    "        for epoch in range(epochs):\n",
    "            total_loss = 0\n",
    "            for batch_x, batch_y in dataset:\n",
    "                with tf.GradientTape() as tape:\n",
    "                    outputs = self.build_model(batch_x)\n",
    "                    loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=outputs, labels=batch_y)) if self.network_type == \"classifier\" else tf.reduce_mean(tf.square(outputs - batch_y))\n",
    "                gradients = tape.gradient(loss, list(self.weights.values()) + list(self.biases.values()))\n",
    "                optimizer.apply_gradients(zip(gradients, list(self.weights.values()) + list(self.biases.values())))\n",
    "                total_loss += loss.numpy()\n",
    "            if verbose:\n",
    "                print(f\"Epoch {epoch+1}/{epochs}, Loss: {total_loss / len(X_train):.6f}\")\n",
    "        print(\"Training Complete!\")\n",
    "    \n",
    "    def predict(self, X_test):\n",
    "        return self.build_model(X_test).numpy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "brain_one = NeuralNetwork(2 , 1 , [10] , network_type = 'classification')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = [[1,2],[2,3],[3,4],[4,5]]\n",
    "y_train = [[3],[5],[7],[9]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1000/1000, Loss: 0.024380\n",
      "Training Complete!\n"
     ]
    }
   ],
   "source": [
    "x_train_tensor = tf.convert_to_tensor(x_train, dtype=tf.float32)\n",
    "y_train_tensor = tf.convert_to_tensor(y_train, dtype=tf.float32)\n",
    "\n",
    "brain_one.train(x_train_tensor, y_train_tensor, epochs=1000, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test = [2,4]\n",
    "x_test_tensor = tf.convert_to_tensor(x_test , dtype=tf.float32)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[6.13254]], dtype=float32)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Reshape x_test_tensor to match the input dimensions of the network\n",
    "x_test_tensor_reshaped = tf.reshape(x_test_tensor, (1, 2))\n",
    "\n",
    "# Predict using the reshaped tensor\n",
    "brain_one.predict(x_test_tensor_reshaped)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframe = pd.read_csv(\"/Users/sriramkurnella/AI/Machine Learning A-Z (Codes and Datasets)/Part 2 - Regression/Section 6 - Polynomial Regression/Python/Position_Salaries.csv\")\n",
    "X = dataframe.iloc[:, 1:2].values\n",
    "y = dataframe.iloc[:, 2].values\n",
    "\n",
    "x_train = tf.convert_to_tensor(X , dtype=tf.float32)\n",
    "y_train = tf.convert_to_tensor(y , dtype=tf.float32)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Position</th>\n",
       "      <th>Level</th>\n",
       "      <th>Salary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Business Analyst</td>\n",
       "      <td>1</td>\n",
       "      <td>45000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Junior Consultant</td>\n",
       "      <td>2</td>\n",
       "      <td>50000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Senior Consultant</td>\n",
       "      <td>3</td>\n",
       "      <td>60000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Manager</td>\n",
       "      <td>4</td>\n",
       "      <td>80000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Country Manager</td>\n",
       "      <td>5</td>\n",
       "      <td>110000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Position  Level  Salary\n",
       "0   Business Analyst      1   45000\n",
       "1  Junior Consultant      2   50000\n",
       "2  Senior Consultant      3   60000\n",
       "3            Manager      4   80000\n",
       "4    Country Manager      5  110000"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataframe.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1000/1000, Loss: 8066224947.200000\n",
      "Training Complete!\n"
     ]
    }
   ],
   "source": [
    "brain_two = NeuralNetwork(1 , 1 , [10 , 10] , network_type = 'regression')\n",
    "brain_two.train(x_train , y_train , epochs = 1000 , learning_rate = 0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test = [2]\n",
    "x_test_tensor = tf.convert_to_tensor(x_test , dtype=tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[249499.64]], dtype=float32)"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "brain_two.predict(tf.reshape(x_test_tensor, (1, 1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.datasets import mnist\n",
    "\n",
    "# Load MNIST Dataset\n",
    "(train_inputs, train_outputs), (test_inputs, test_outputs) = mnist.load_data()\n",
    "\n",
    "# Flatten images from (28,28) to (784,) and normalize\n",
    "train_inputs = train_inputs.reshape(60000, 784).T / 255.0  # Shape: (784, 60000)\n",
    "test_inputs = test_inputs.reshape(10000, 784).T / 255.0    # Shape: (784, 10000)\n",
    "\n",
    "# Convert labels to one-hot encoding (10 classes)\n",
    "train_outputs = np.eye(10)[train_outputs].T  # Shape: (10, 60000)\n",
    "test_outputs = np.eye(10)[test_outputs].T    # Shape: (10, 10000)\n",
    "\n",
    "# Convert to TensorFlow tensors\n",
    "train_inputs = tf.convert_to_tensor(train_inputs, dtype=tf.float32)\n",
    "train_outputs = tf.convert_to_tensor(train_outputs, dtype=tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Intra op parallelism cannot be modified after initialization.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[108], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Create the neural network\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m brain_three \u001b[38;5;241m=\u001b[39m NeuralNetwork(\u001b[38;5;241m784\u001b[39m, \u001b[38;5;241m10\u001b[39m, [\u001b[38;5;241m64\u001b[39m, \u001b[38;5;241m16\u001b[39m], network_type\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mclassification\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "Cell \u001b[0;32mIn[106], line 14\u001b[0m, in \u001b[0;36mNeuralNetwork.__init__\u001b[0;34m(self, input_size, output_size, hidden_layers, network_type)\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhidden_layers \u001b[38;5;241m=\u001b[39m hidden_layers\n\u001b[1;32m     12\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnetwork_type \u001b[38;5;241m=\u001b[39m network_type\n\u001b[0;32m---> 14\u001b[0m tf\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mthreading\u001b[38;5;241m.\u001b[39mset_intra_op_parallelism_threads(\u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m     15\u001b[0m tf\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mthreading\u001b[38;5;241m.\u001b[39mset_inter_op_parallelism_threads(\u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m     16\u001b[0m tf\u001b[38;5;241m.\u001b[39mkeras\u001b[38;5;241m.\u001b[39mmixed_precision\u001b[38;5;241m.\u001b[39mset_global_policy(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmixed_float16\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/site-packages/tensorflow/python/framework/config.py:129\u001b[0m, in \u001b[0;36mset_intra_op_parallelism_threads\u001b[0;34m(num_threads)\u001b[0m\n\u001b[1;32m    118\u001b[0m \u001b[38;5;129m@tf_export\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mconfig.threading.set_intra_op_parallelism_threads\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m    119\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mset_intra_op_parallelism_threads\u001b[39m(num_threads):\n\u001b[1;32m    120\u001b[0m \u001b[38;5;250m  \u001b[39m\u001b[38;5;124;03m\"\"\"Set number of threads used within an individual op for parallelism.\u001b[39;00m\n\u001b[1;32m    121\u001b[0m \n\u001b[1;32m    122\u001b[0m \u001b[38;5;124;03m  Certain operations like matrix multiplication and reductions can utilize\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    127\u001b[0m \u001b[38;5;124;03m    num_threads: Number of parallel threads\u001b[39;00m\n\u001b[1;32m    128\u001b[0m \u001b[38;5;124;03m  \"\"\"\u001b[39;00m\n\u001b[0;32m--> 129\u001b[0m   context\u001b[38;5;241m.\u001b[39mcontext()\u001b[38;5;241m.\u001b[39mintra_op_parallelism_threads \u001b[38;5;241m=\u001b[39m num_threads\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/site-packages/tensorflow/python/eager/context.py:2233\u001b[0m, in \u001b[0;36mContext.intra_op_parallelism_threads\u001b[0;34m(self, num_threads)\u001b[0m\n\u001b[1;32m   2230\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[1;32m   2232\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_context_handle \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 2233\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[1;32m   2234\u001b[0m       \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIntra op parallelism cannot be modified after initialization.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   2235\u001b[0m   )\n\u001b[1;32m   2237\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_intra_op_parallelism_threads \u001b[38;5;241m=\u001b[39m num_threads\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Intra op parallelism cannot be modified after initialization."
     ]
    }
   ],
   "source": [
    "\n",
    "# Create the neural network\n",
    "brain_three = NeuralNetwork(784, 10, [64, 16], network_type='classification')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20/1000, Loss: 0.000251\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[75], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m train_inputs_transposed \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mtranspose(train_inputs)\n\u001b[1;32m      2\u001b[0m train_outputs_transposed \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mtranspose(train_outputs)\n\u001b[0;32m----> 4\u001b[0m brain_three\u001b[38;5;241m.\u001b[39mtrain(train_inputs_transposed, train_outputs_transposed, epochs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1000\u001b[39m, verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, learning_rate\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.01\u001b[39m)\n",
      "Cell \u001b[0;32mIn[49], line 130\u001b[0m, in \u001b[0;36mNeuralNetwork.train\u001b[0;34m(self, X_train, y_train, epochs, batch_size, verbose, learning_rate)\u001b[0m\n\u001b[1;32m    127\u001b[0m             loss \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mreduce_mean(tf\u001b[38;5;241m.\u001b[39msquare(outputs \u001b[38;5;241m-\u001b[39m batch_y))  \u001b[38;5;66;03m# MSE for regression\u001b[39;00m\n\u001b[1;32m    129\u001b[0m     gradients \u001b[38;5;241m=\u001b[39m tape\u001b[38;5;241m.\u001b[39mgradient(loss, \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mweights\u001b[38;5;241m.\u001b[39mvalues()) \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbiases\u001b[38;5;241m.\u001b[39mvalues()))\n\u001b[0;32m--> 130\u001b[0m     optimizer\u001b[38;5;241m.\u001b[39mapply_gradients(\u001b[38;5;28mzip\u001b[39m(gradients, \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mweights\u001b[38;5;241m.\u001b[39mvalues()) \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbiases\u001b[38;5;241m.\u001b[39mvalues())))\n\u001b[1;32m    131\u001b[0m     total_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m loss\u001b[38;5;241m.\u001b[39mnumpy()\n\u001b[1;32m    133\u001b[0m avg_loss \u001b[38;5;241m=\u001b[39m total_loss \u001b[38;5;241m/\u001b[39m \u001b[38;5;28mlen\u001b[39m(X_train)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/site-packages/keras/src/optimizers/base_optimizer.py:383\u001b[0m, in \u001b[0;36mBaseOptimizer.apply_gradients\u001b[0;34m(self, grads_and_vars)\u001b[0m\n\u001b[1;32m    381\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mapply_gradients\u001b[39m(\u001b[38;5;28mself\u001b[39m, grads_and_vars):\n\u001b[1;32m    382\u001b[0m     grads, trainable_variables \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mzip\u001b[39m(\u001b[38;5;241m*\u001b[39mgrads_and_vars)\n\u001b[0;32m--> 383\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mapply(grads, trainable_variables)\n\u001b[1;32m    384\u001b[0m     \u001b[38;5;66;03m# Return iterations for compat with tf.keras.\u001b[39;00m\n\u001b[1;32m    385\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_iterations\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/site-packages/keras/src/optimizers/base_optimizer.py:448\u001b[0m, in \u001b[0;36mBaseOptimizer.apply\u001b[0;34m(self, grads, trainable_variables)\u001b[0m\n\u001b[1;32m    445\u001b[0m     grads \u001b[38;5;241m=\u001b[39m [g \u001b[38;5;28;01mif\u001b[39;00m g \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m g \u001b[38;5;241m/\u001b[39m scale \u001b[38;5;28;01mfor\u001b[39;00m g \u001b[38;5;129;01min\u001b[39;00m grads]\n\u001b[1;32m    447\u001b[0m \u001b[38;5;66;03m# Apply gradient updates.\u001b[39;00m\n\u001b[0;32m--> 448\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend_apply_gradients(grads, trainable_variables)\n\u001b[1;32m    449\u001b[0m \u001b[38;5;66;03m# Apply variable constraints after applying gradients.\u001b[39;00m\n\u001b[1;32m    450\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m variable \u001b[38;5;129;01min\u001b[39;00m trainable_variables:\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/site-packages/keras/src/optimizers/base_optimizer.py:511\u001b[0m, in \u001b[0;36mBaseOptimizer._backend_apply_gradients\u001b[0;34m(self, grads, trainable_variables)\u001b[0m\n\u001b[1;32m    508\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_apply_weight_decay(trainable_variables)\n\u001b[1;32m    510\u001b[0m     \u001b[38;5;66;03m# Run update step.\u001b[39;00m\n\u001b[0;32m--> 511\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend_update_step(\n\u001b[1;32m    512\u001b[0m         grads, trainable_variables, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlearning_rate\n\u001b[1;32m    513\u001b[0m     )\n\u001b[1;32m    515\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39muse_ema:\n\u001b[1;32m    516\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_update_model_variables_moving_average(\n\u001b[1;32m    517\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_trainable_variables\n\u001b[1;32m    518\u001b[0m     )\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/site-packages/keras/src/backend/tensorflow/optimizer.py:120\u001b[0m, in \u001b[0;36mTFOptimizer._backend_update_step\u001b[0;34m(self, grads, trainable_variables, learning_rate)\u001b[0m\n\u001b[1;32m    118\u001b[0m grads_and_vars \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mzip\u001b[39m(grads, trainable_variables))\n\u001b[1;32m    119\u001b[0m grads_and_vars \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_all_reduce_sum_gradients(grads_and_vars)\n\u001b[0;32m--> 120\u001b[0m tf\u001b[38;5;241m.\u001b[39m__internal__\u001b[38;5;241m.\u001b[39mdistribute\u001b[38;5;241m.\u001b[39minterim\u001b[38;5;241m.\u001b[39mmaybe_merge_call(\n\u001b[1;32m    121\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_distributed_tf_update_step,\n\u001b[1;32m    122\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_distribution_strategy,\n\u001b[1;32m    123\u001b[0m     grads_and_vars,\n\u001b[1;32m    124\u001b[0m     learning_rate,\n\u001b[1;32m    125\u001b[0m )\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/site-packages/tensorflow/python/distribute/merge_call_interim.py:51\u001b[0m, in \u001b[0;36mmaybe_merge_call\u001b[0;34m(fn, strategy, *args, **kwargs)\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Maybe invoke `fn` via `merge_call` which may or may not be fulfilled.\u001b[39;00m\n\u001b[1;32m     32\u001b[0m \n\u001b[1;32m     33\u001b[0m \u001b[38;5;124;03mThe caller of this utility function requests to invoke `fn` via `merge_call`\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     48\u001b[0m \u001b[38;5;124;03m  The return value of the `fn` call.\u001b[39;00m\n\u001b[1;32m     49\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     50\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m strategy_supports_no_merge_call():\n\u001b[0;32m---> 51\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m fn(strategy, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m     52\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     53\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m distribute_lib\u001b[38;5;241m.\u001b[39mget_replica_context()\u001b[38;5;241m.\u001b[39mmerge_call(\n\u001b[1;32m     54\u001b[0m       fn, args\u001b[38;5;241m=\u001b[39margs, kwargs\u001b[38;5;241m=\u001b[39mkwargs)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/site-packages/keras/src/backend/tensorflow/optimizer.py:134\u001b[0m, in \u001b[0;36mTFOptimizer._distributed_tf_update_step\u001b[0;34m(self, distribution, grads_and_vars, learning_rate)\u001b[0m\n\u001b[1;32m    131\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mupdate_step(grad, var, learning_rate)\n\u001b[1;32m    133\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m grad, var \u001b[38;5;129;01min\u001b[39;00m grads_and_vars:\n\u001b[0;32m--> 134\u001b[0m     distribution\u001b[38;5;241m.\u001b[39mextended\u001b[38;5;241m.\u001b[39mupdate(\n\u001b[1;32m    135\u001b[0m         var,\n\u001b[1;32m    136\u001b[0m         apply_grad_to_update_var,\n\u001b[1;32m    137\u001b[0m         args\u001b[38;5;241m=\u001b[39m(grad, learning_rate),\n\u001b[1;32m    138\u001b[0m         group\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m    139\u001b[0m     )\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/site-packages/tensorflow/python/distribute/distribute_lib.py:3005\u001b[0m, in \u001b[0;36mStrategyExtendedV2.update\u001b[0;34m(self, var, fn, args, kwargs, group)\u001b[0m\n\u001b[1;32m   3002\u001b[0m   fn \u001b[38;5;241m=\u001b[39m autograph\u001b[38;5;241m.\u001b[39mtf_convert(\n\u001b[1;32m   3003\u001b[0m       fn, autograph_ctx\u001b[38;5;241m.\u001b[39mcontrol_status_ctx(), convert_by_default\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m   3004\u001b[0m   \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_container_strategy()\u001b[38;5;241m.\u001b[39mscope():\n\u001b[0;32m-> 3005\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_update(var, fn, args, kwargs, group)\n\u001b[1;32m   3006\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   3007\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_replica_ctx_update(\n\u001b[1;32m   3008\u001b[0m       var, fn, args\u001b[38;5;241m=\u001b[39margs, kwargs\u001b[38;5;241m=\u001b[39mkwargs, group\u001b[38;5;241m=\u001b[39mgroup)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/site-packages/tensorflow/python/distribute/distribute_lib.py:4075\u001b[0m, in \u001b[0;36m_DefaultDistributionExtended._update\u001b[0;34m(self, var, fn, args, kwargs, group)\u001b[0m\n\u001b[1;32m   4072\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_update\u001b[39m(\u001b[38;5;28mself\u001b[39m, var, fn, args, kwargs, group):\n\u001b[1;32m   4073\u001b[0m   \u001b[38;5;66;03m# The implementations of _update() and _update_non_slot() are identical\u001b[39;00m\n\u001b[1;32m   4074\u001b[0m   \u001b[38;5;66;03m# except _update() passes `var` as the first argument to `fn()`.\u001b[39;00m\n\u001b[0;32m-> 4075\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_update_non_slot(var, fn, (var,) \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mtuple\u001b[39m(args), kwargs, group)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/site-packages/tensorflow/python/distribute/distribute_lib.py:4081\u001b[0m, in \u001b[0;36m_DefaultDistributionExtended._update_non_slot\u001b[0;34m(self, colocate_with, fn, args, kwargs, should_group)\u001b[0m\n\u001b[1;32m   4077\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_update_non_slot\u001b[39m(\u001b[38;5;28mself\u001b[39m, colocate_with, fn, args, kwargs, should_group):\n\u001b[1;32m   4078\u001b[0m   \u001b[38;5;66;03m# TODO(josh11b): Figure out what we should be passing to UpdateContext()\u001b[39;00m\n\u001b[1;32m   4079\u001b[0m   \u001b[38;5;66;03m# once that value is used for something.\u001b[39;00m\n\u001b[1;32m   4080\u001b[0m   \u001b[38;5;28;01mwith\u001b[39;00m UpdateContext(colocate_with):\n\u001b[0;32m-> 4081\u001b[0m     result \u001b[38;5;241m=\u001b[39m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m   4082\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m should_group:\n\u001b[1;32m   4083\u001b[0m       \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/site-packages/tensorflow/python/autograph/impl/api.py:596\u001b[0m, in \u001b[0;36mcall_with_unspecified_conversion_status.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    594\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrapper\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    595\u001b[0m   \u001b[38;5;28;01mwith\u001b[39;00m ag_ctx\u001b[38;5;241m.\u001b[39mControlStatusCtx(status\u001b[38;5;241m=\u001b[39mag_ctx\u001b[38;5;241m.\u001b[39mStatus\u001b[38;5;241m.\u001b[39mUNSPECIFIED):\n\u001b[0;32m--> 596\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/site-packages/keras/src/backend/tensorflow/optimizer.py:131\u001b[0m, in \u001b[0;36mTFOptimizer._distributed_tf_update_step.<locals>.apply_grad_to_update_var\u001b[0;34m(var, grad, learning_rate)\u001b[0m\n\u001b[1;32m    130\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mapply_grad_to_update_var\u001b[39m(var, grad, learning_rate):\n\u001b[0;32m--> 131\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mupdate_step(grad, var, learning_rate)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/site-packages/keras/src/optimizers/adam.py:121\u001b[0m, in \u001b[0;36mAdam.update_step\u001b[0;34m(self, gradient, variable, learning_rate)\u001b[0m\n\u001b[1;32m    118\u001b[0m gradient \u001b[38;5;241m=\u001b[39m ops\u001b[38;5;241m.\u001b[39mcast(gradient, variable\u001b[38;5;241m.\u001b[39mdtype)\n\u001b[1;32m    119\u001b[0m local_step \u001b[38;5;241m=\u001b[39m ops\u001b[38;5;241m.\u001b[39mcast(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39miterations \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m, variable\u001b[38;5;241m.\u001b[39mdtype)\n\u001b[1;32m    120\u001b[0m beta_1_power \u001b[38;5;241m=\u001b[39m ops\u001b[38;5;241m.\u001b[39mpower(\n\u001b[0;32m--> 121\u001b[0m     ops\u001b[38;5;241m.\u001b[39mcast(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbeta_1, variable\u001b[38;5;241m.\u001b[39mdtype), local_step\n\u001b[1;32m    122\u001b[0m )\n\u001b[1;32m    123\u001b[0m beta_2_power \u001b[38;5;241m=\u001b[39m ops\u001b[38;5;241m.\u001b[39mpower(\n\u001b[1;32m    124\u001b[0m     ops\u001b[38;5;241m.\u001b[39mcast(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbeta_2, variable\u001b[38;5;241m.\u001b[39mdtype), local_step\n\u001b[1;32m    125\u001b[0m )\n\u001b[1;32m    127\u001b[0m m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_momentums[\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_variable_index(variable)]\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/site-packages/keras/src/ops/core.py:803\u001b[0m, in \u001b[0;36mcast\u001b[0;34m(x, dtype)\u001b[0m\n\u001b[1;32m    801\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m any_symbolic_tensors((x,)):\n\u001b[1;32m    802\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m Cast(dtype\u001b[38;5;241m=\u001b[39mdtype)(x)\n\u001b[0;32m--> 803\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m backend\u001b[38;5;241m.\u001b[39mcore\u001b[38;5;241m.\u001b[39mcast(x, dtype)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/site-packages/keras/src/backend/tensorflow/core.py:204\u001b[0m, in \u001b[0;36mcast\u001b[0;34m(x, dtype)\u001b[0m\n\u001b[1;32m    202\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m x\n\u001b[1;32m    203\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 204\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mcast(x, dtype\u001b[38;5;241m=\u001b[39mdtype)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/site-packages/tensorflow/python/util/traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/site-packages/tensorflow/python/util/dispatch.py:1260\u001b[0m, in \u001b[0;36madd_dispatch_support.<locals>.decorator.<locals>.op_dispatch_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m   1258\u001b[0m \u001b[38;5;66;03m# Fallback dispatch system (dispatch v1):\u001b[39;00m\n\u001b[1;32m   1259\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1260\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m dispatch_target(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m   1261\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (\u001b[38;5;167;01mTypeError\u001b[39;00m, \u001b[38;5;167;01mValueError\u001b[39;00m):\n\u001b[1;32m   1262\u001b[0m   \u001b[38;5;66;03m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001b[39;00m\n\u001b[1;32m   1263\u001b[0m   \u001b[38;5;66;03m# TypeError, when given unexpected types.  So we need to catch both.\u001b[39;00m\n\u001b[1;32m   1264\u001b[0m   result \u001b[38;5;241m=\u001b[39m dispatch(op_dispatch_handler, args, kwargs)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/site-packages/tensorflow/python/ops/math_ops.py:1012\u001b[0m, in \u001b[0;36mcast\u001b[0;34m(x, dtype, name)\u001b[0m\n\u001b[1;32m   1006\u001b[0m   x \u001b[38;5;241m=\u001b[39m indexed_slices\u001b[38;5;241m.\u001b[39mIndexedSlices(values_cast, x\u001b[38;5;241m.\u001b[39mindices, x\u001b[38;5;241m.\u001b[39mdense_shape)\n\u001b[1;32m   1007\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1008\u001b[0m   \u001b[38;5;66;03m# TODO(josh11b): If x is not already a Tensor, we could return\u001b[39;00m\n\u001b[1;32m   1009\u001b[0m   \u001b[38;5;66;03m# ops.convert_to_tensor(x, dtype=dtype, ...)  here, but that\u001b[39;00m\n\u001b[1;32m   1010\u001b[0m   \u001b[38;5;66;03m# allows some conversions that cast() can't do, e.g. casting numbers to\u001b[39;00m\n\u001b[1;32m   1011\u001b[0m   \u001b[38;5;66;03m# strings.\u001b[39;00m\n\u001b[0;32m-> 1012\u001b[0m   x \u001b[38;5;241m=\u001b[39m ops\u001b[38;5;241m.\u001b[39mconvert_to_tensor(x, name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mx\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   1013\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m x\u001b[38;5;241m.\u001b[39mdtype\u001b[38;5;241m.\u001b[39mis_complex \u001b[38;5;129;01mand\u001b[39;00m base_type\u001b[38;5;241m.\u001b[39mis_floating:\n\u001b[1;32m   1014\u001b[0m     logging\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[1;32m   1015\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mYou are casting an input of type \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mx\u001b[38;5;241m.\u001b[39mdtype\u001b[38;5;241m.\u001b[39mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m to an \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1016\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mincompatible dtype \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mbase_type\u001b[38;5;241m.\u001b[39mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.  This will \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1017\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdiscard the imaginary part and may not be what you \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1018\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mintended.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1019\u001b[0m     )\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/site-packages/tensorflow/python/profiler/trace.py:183\u001b[0m, in \u001b[0;36mtrace_wrapper.<locals>.inner_wrapper.<locals>.wrapped\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    181\u001b[0m   \u001b[38;5;28;01mwith\u001b[39;00m Trace(trace_name, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mtrace_kwargs):\n\u001b[1;32m    182\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m--> 183\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/site-packages/tensorflow/python/framework/ops.py:736\u001b[0m, in \u001b[0;36mconvert_to_tensor\u001b[0;34m(value, dtype, name, as_ref, preferred_dtype, dtype_hint, ctx, accepted_result_types)\u001b[0m\n\u001b[1;32m    734\u001b[0m \u001b[38;5;66;03m# TODO(b/142518781): Fix all call-sites and remove redundant arg\u001b[39;00m\n\u001b[1;32m    735\u001b[0m preferred_dtype \u001b[38;5;241m=\u001b[39m preferred_dtype \u001b[38;5;129;01mor\u001b[39;00m dtype_hint\n\u001b[0;32m--> 736\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m tensor_conversion_registry\u001b[38;5;241m.\u001b[39mconvert(\n\u001b[1;32m    737\u001b[0m     value, dtype, name, as_ref, preferred_dtype, accepted_result_types\n\u001b[1;32m    738\u001b[0m )\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/site-packages/tensorflow/python/framework/tensor_conversion_registry.py:164\u001b[0m, in \u001b[0;36mconvert\u001b[0;34m(value, dtype, name, as_ref, preferred_dtype, accepted_result_types)\u001b[0m\n\u001b[1;32m    160\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_add_error_prefix\u001b[39m(msg, \u001b[38;5;241m*\u001b[39m, name\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m    161\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m msg \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmsg\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m--> 164\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mconvert\u001b[39m(value,\n\u001b[1;32m    165\u001b[0m             dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    166\u001b[0m             name\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    167\u001b[0m             as_ref\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m    168\u001b[0m             preferred_dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    169\u001b[0m             accepted_result_types\u001b[38;5;241m=\u001b[39m(core\u001b[38;5;241m.\u001b[39mSymbol,)):\n\u001b[1;32m    170\u001b[0m \u001b[38;5;250m  \u001b[39m\u001b[38;5;124;03m\"\"\"Converts `value` to a `Tensor` using registered conversion functions.\u001b[39;00m\n\u001b[1;32m    171\u001b[0m \n\u001b[1;32m    172\u001b[0m \u001b[38;5;124;03m  Args:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    199\u001b[0m \u001b[38;5;124;03m      value.\u001b[39;00m\n\u001b[1;32m    200\u001b[0m \u001b[38;5;124;03m  \"\"\"\u001b[39;00m\n\u001b[1;32m    202\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m dtype \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "train_inputs_transposed = tf.transpose(train_inputs)\n",
    "train_outputs_transposed = tf.transpose(train_outputs)\n",
    "\n",
    "brain_three.train(train_inputs_transposed, train_outputs_transposed, epochs=1000, verbose=True, learning_rate=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "number = 49\n",
    "plt.figure()\n",
    "plt.imshow(test_inputs[:, number].reshape(28, 28))\n",
    "plt.colorbar()\n",
    "plt.grid(False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 9.9100545e-03, -1.3100803e-03, -3.4118593e-03, -9.3183443e-03,\n",
       "         1.0609727e+00, -2.6644856e-02,  3.3519082e-02,  1.1526361e-02,\n",
       "        -4.8178434e-04, -6.6833124e-03]], dtype=float32)"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Ensure the test_inputs tensor is of type float32\n",
    "test_inputs_float32 = tf.convert_to_tensor(test_inputs, dtype=tf.float32)\n",
    "\n",
    "# Reshape the selected test input to match the expected input dimensions of the model\n",
    "test_input_reshaped = tf.reshape(test_inputs_float32[:, number], (1, -1))\n",
    "\n",
    "# Predict using the reshaped tensor\n",
    "brain_three.predict(test_input_reshaped)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
